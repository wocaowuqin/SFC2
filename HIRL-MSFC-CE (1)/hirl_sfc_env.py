#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# @File    : hirl_sfc_env.py - FIXED & INTEGRATED VERSION (AttributeError Fix)
from reward_critic_enhanced import RewardCritic
import os
import logging
import random
import numpy as np
import scipy.io as sio
from pathlib import Path
from typing import Dict, List, Tuple, Set, Optional, Any
import pickle

import gym
from gym import spaces

from failure_visualizer import FailureVisualizer

from vnf_metrics_logger import VNFMetricsLogger  # [æ–°å¢] å¯¼å…¥ Logger
# [æ–°å¢] å¯¼å…¥å¤‡ä»½ç³»ç»Ÿ
from sfc_backup_system import BackupPolicy

# ----------------------------------------------------
# Import Expert Modules
# ----------------------------------------------------
try:
    from expert_msfce import MSFCE_Solver, parse_mat_request
except ImportError:
    class MSFCE_Solver:
        pass

    def parse_mat_request(x):
        return x

# ----------------------------------------------------
# Logging
# ----------------------------------------------------
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


# ----------------------------------------------------
# PathManager
# ----------------------------------------------------
class PathManager:
    """ç‹¬ç«‹çš„è·¯å¾„ç®¡ç†å™¨, ç¡®ä¿è·¯å¾„ç´¢å¼•çš„ä¸€è‡´æ€§"""

    def __init__(self, max_paths=10):
        self.max_paths = max_paths
        self.paths: List[List[int]] = []
        self.path_to_idx: Dict[tuple, int] = {}

    def add_path(self, path: List[int]) -> int:
        path_tuple = tuple(path)
        if path_tuple in self.path_to_idx:
            return self.path_to_idx[path_tuple]
        if len(self.paths) < self.max_paths:
            idx = len(self.paths)
            self.paths.append(path)
            self.path_to_idx[path_tuple] = idx
            return idx
        return 0

    def get_path(self, idx: int) -> Optional[List[int]]:
        if 0 <= idx < len(self.paths):
            return self.paths[idx]
        return None

    def get_all_paths(self) -> List[List[int]]:
        return self.paths.copy()

    def reset(self):
        self.paths.clear()
        self.path_to_idx.clear()

    def __len__(self):
        return len(self.paths)


# ----------------------------------------------------
# SFC_HIRL_Env (Fixed & Optimized & Integrated)
# ----------------------------------------------------
class SFC_HIRL_Env(gym.Env):
    """
    åˆ†å±‚ SFC ç¯å¢ƒï¼ˆé›†æˆ BackupPolicy ç‰ˆï¼‰ï¼š
    âœ… é›†æˆ sfc_backup_system å®ç°é«˜é²æ£’æ€§å…œåº•
    âœ… ä¿®å¤èµ„æºçŠ¶æ€ç±»å‹å…¼å®¹æ€§
    âœ… ä¿®å¤ AttributeError: set_tree -> set_current_tree
    """

    def __init__(self, input_dir: Path, topo: np.ndarray, dc_nodes: List[int], capacities: Dict):
        super(SFC_HIRL_Env, self).__init__()

        # =========================================================
        # 1. åŸºç¡€é…ç½®ä¸è·¯å¾„ (Config & Paths)
        # =========================================================
        # [æ–°å¢] é…ç½®ä½ çš„è¾“å‡ºè·¯å¾„ (ä½¿ç”¨ raw string é˜²æ­¢è½¬ä¹‰)
        self.failure_output_dir = r"E:\pycharmworkspace\SFC-master\HIRL-MSFC-CE (1)\out_failue"

        # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹
        import os
        os.makedirs(self.failure_output_dir, exist_ok=True)

        # [æ–°å¢] æ¸²æŸ“å¼€å…³
        self.enable_render = True

        # =========================================================
        # 2. åˆå§‹åŒ–ä¸“å®¶ç³»ç»Ÿ (Expert System) - è·å–ç½‘ç»œç»´åº¦
        # =========================================================
        # å¿…é¡»æœ€å…ˆåˆå§‹åŒ–ï¼Œå› ä¸ºå®ƒå†³å®šäº† self.n (èŠ‚ç‚¹æ•°) å’Œ self.L (é“¾è·¯æ•°)
        self.expert = MSFCE_Solver(input_dir / "US_Backbone_path.mat", topo, dc_nodes, capacities)

        self.T = 400
        self.n, self.L, self.K_vnf = self.expert.node_num, self.expert.link_num, self.expert.type_num
        self.K_path = self.expert.k_path_count

        # =========================================================
        # 3. èµ„æºçŠ¶æ€åˆå§‹åŒ– (Resource State)
        # =========================================================
        # å¿…é¡»åœ¨ Logger ä¹‹å‰åˆå§‹åŒ–ï¼Œå› ä¸º Logger éœ€è¦è¯»å–è¿™äº›å®¹é‡å€¼
        self.B_cap = capacities['bandwidth']
        self.C_cap = capacities['cpu']
        self.M_cap = capacities['memory']

        self.B = np.full(self.L, self.B_cap, dtype=float)
        self.C = np.full(self.n, self.C_cap, dtype=float)
        self.M = np.full(self.n, self.M_cap, dtype=float)
        self.hvt_all = np.zeros((self.n, self.K_vnf), dtype=int)
        self.link_ref_count = np.zeros(self.L, dtype=int)

        # =========================================================
        # 4. åˆå§‹åŒ– VNFMetricsLogger (Logger)
        # =========================================================
        # [æ–°å¢] è®¡ç®—ç½‘ç»œæ€»èµ„æºç”¨äº Logger åˆå§‹åŒ–
        # é˜²å¾¡æ€§åˆ¤æ–­ï¼šå¤„ç† numpy array æˆ– æ ‡é‡
        total_cpu = np.sum(self.C_cap) if isinstance(self.C_cap, (np.ndarray, list)) else self.n * self.C_cap
        total_bw = np.sum(self.B_cap) if isinstance(self.B_cap, (np.ndarray, list)) else self.L * self.B_cap
        total_mem = np.sum(self.M_cap) if isinstance(self.M_cap, (np.ndarray, list)) else self.n * self.M_cap

        network_info = {
            "total_nodes": self.n,
            "total_cpu": float(total_cpu),
            "total_bw": float(total_bw),
            "total_mem": float(total_mem)
        }
        self.metrics_logger = VNFMetricsLogger(network_info)
        # ğŸ”¥ æ–°å¢: å¤šç›®æ ‡é›†åˆç®¡ç†
        self.destination_set: Set[int] = set()  # æ‰€æœ‰ç›®æ ‡èŠ‚ç‚¹
        self.served_destinations: Set[int] = set()  # å·²æœåŠ¡çš„ç›®æ ‡

        # ğŸ”¥ æ–°å¢: VNFå…±äº«çŠ¶æ€
        self.vnf_sharing_map: Dict[Tuple[int, int], Set[int]] = {}
        # Key: (node_id, vnf_type), Value: set of destination indices sharing this VNF

        # ğŸ”¥ æ–°å¢: å…±äº«ç­–ç•¥çŠ¶æ€
        self.sharing_strategy: int = 0  # 0-3å¯¹åº”4ç§ç­–ç•¥

        # =========================================================
        # 5. åˆå§‹åŒ–å¯è§†åŒ–å™¨ (Visualizer)
        # =========================================================
        # [æ–°å¢] å°†é‚»æ¥çŸ©é˜µ topo è½¬æ¢ä¸ºè¾¹åˆ—è¡¨
        rows, cols = np.where(topo > 0)
        edges = list(zip(rows.tolist(), cols.tolist()))

        # å®ä¾‹åŒ–ï¼Œæ— åæ ‡æ•°æ®ä¼  None è®©å…¶è‡ªåŠ¨å¸ƒå±€
        self.visualizer = FailureVisualizer(topo_edges=edges, node_positions=None)

        # =========================================================
        # 6. ç»Ÿè®¡è®¡æ•°å™¨ (Statistics)
        # =========================================================
        # [æ–°å¢] è¯¦ç»†ç»Ÿè®¡è®¡æ•°å™¨ (ç”¨äºè®¡ç®—æˆåŠŸç‡)
        self.stats_req_total = 0  # æ€»è¯·æ±‚æ•°
        self.stats_req_perfect = 0  # å®Œå…¨æˆåŠŸçš„è¯·æ±‚æ•°
        self.stats_sub_total = 0  # æ€»å­ä»»åŠ¡æ•°
        self.stats_sub_success = 0  # æˆåŠŸçš„å­ä»»åŠ¡æ•°

        self.stats_total_subtasks = 0  # å…¼å®¹æ—§ä»£ç è®¡æ•°å™¨
        self.stats_backup_activated = 0  # å¤‡ä»½è§¦å‘æ¬¡æ•°
        self.stats_backup_succeeded = 0  # å¤‡ä»½æˆåŠŸæ¬¡æ•°

        self.total_requests_seen = 0
        self.total_requests_accepted = 0
        self.total_dest_seen = 0
        self.total_dest_accepted = 0

        # =========================================================
        # 7. ç­–ç•¥ç»„ä»¶åˆå§‹åŒ– (Policy Components)
        # =========================================================
        # [æ–°å¢] åˆå§‹åŒ–å¥–åŠ±å‡½æ•°
        self.reward_critic = RewardCritic(training_phase=1, epoch=0, max_epochs=1200)

        # [æ–°å¢] åˆå§‹åŒ–å¤‡ä»½ç­–ç•¥ç³»ç»Ÿ
        self.backup_metrics = {"activation_count": 0, "success_count": 0, "total": 0}
        self.backup_policy = BackupPolicy(
            expert=self.expert,
            n=self.n,
            L=self.L,
            K_vnf=self.K_vnf,
            dc_nodes=dc_nodes
        )
        logger.info("BackupPolicy system initialized.")

        # âœ… ä¿®å¤: ä» PathDB æ„å»ºæœ€çŸ­è·ç¦»çŸ©é˜µ
        self._build_shortest_dist_matrix()

        # =========================================================
        # 8. æ•°æ®åŠ è½½ (Data Loading)
        # =========================================================
        self._eval_cache = {}
        self.expert_randomness = 0.1

        try:
            # åŠ è½½è¯·æ±‚æ•°æ®
            req_path = input_dir / "sorted_requests.pkl"
            if not req_path.exists():
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¯·æ±‚æ–‡ä»¶: {req_path}")

            with open(req_path, 'rb') as f:
                self.requests = pickle.load(f)
            self.req_map = {r['id']: r for r in self.requests}

            # åŠ è½½äº‹ä»¶æ•°æ®
            event_path = input_dir / "event_list.pkl"
            if not event_path.exists():
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°äº‹ä»¶æ–‡ä»¶: {event_path}")

            with open(event_path, 'rb') as f:
                raw_events = pickle.load(f)

            self.events = []
            for evt in raw_events:
                arrive_data = evt.get('arrive_event', evt.get('arrive', []))
                leave_data = evt.get('leave_event', evt.get('leave', []))
                self.events.append({
                    'arrive': np.array(arrive_data, dtype=int).flatten(),
                    'leave': np.array(leave_data, dtype=int).flatten()
                })
            logger.info(f"æˆåŠŸåŠ è½½æ•°æ®: {len(self.requests)} è¯·æ±‚, {len(self.events)} æ—¶é—´æ­¥")

        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            raise

        # =========================================================
        # 9. çŠ¶æ€ä¸ç©ºé—´å®šä¹‰ (State & Spaces)
        # =========================================================
        # HIRL è¿è¡ŒçŠ¶æ€
        self.t = 0
        self.current_request: Optional[Dict] = None
        self.unadded_dest_indices: Set[int] = set()
        self.current_tree: Optional[Dict] = None
        self.nodes_on_tree: Set[int] = set()
        self.served_requests: List[Tuple[Dict, Dict]] = []
        self.current_req_is_perfect = True  # æ ‡è®°ä½

        # PathManager
        self.MAX_PATHS_IN_TREE = 10
        self.path_manager = PathManager(max_paths=self.MAX_PATHS_IN_TREE)

        # åŠ¨ä½œç©ºé—´é…ç½®
        self.NB_HIGH_LEVEL_GOALS = 10
        self.NB_LOW_LEVEL_ACTIONS = self.MAX_PATHS_IN_TREE * self.K_path

        # çŠ¶æ€ç©ºé—´ç»´åº¦
        self.dim_network = self.n + self.n + self.L + self.n * self.K_vnf
        self.dim_request = 10
        self.STATE_VECTOR_SIZE = self.dim_network + self.dim_request

        # Gym spaces
        self.action_space = spaces.Discrete(self.NB_HIGH_LEVEL_GOALS)
        self.observation_space = spaces.Box(low=0.0, high=1.0,
                                            shape=(self.STATE_VECTOR_SIZE,), dtype=np.float32)
    # [æ–°å¢] è·å–å¤‡ä»½ç»Ÿè®¡æŒ‡æ ‡çš„æ–¹æ³•
    def get_backup_metrics(self) -> Dict[str, float]:
        """è®¡ç®—å¹¶è¿”å›å¤‡ä»½ç­–ç•¥çš„è§¦å‘ç‡å’ŒæˆåŠŸç‡"""
        total = max(1, self.stats_total_subtasks)
        activated = self.stats_backup_activated

        # è§¦å‘ç‡ = å¤‡ä»½æ¬¡æ•° / æ€»ä»»åŠ¡æ•°
        activation_rate = (activated / total) * 100.0

        # æˆåŠŸç‡ = å¤‡ä»½æˆåŠŸæ¬¡æ•° / å¤‡ä»½è§¦å‘æ¬¡æ•°
        # (åˆ†æ¯ç”¨ max(1, activated) é˜²æ­¢é™¤é›¶)
        success_rate = 0.0
        if activated > 0:
            success_rate = (self.stats_backup_succeeded / activated) * 100.0

        return {
            'activation_rate': activation_rate,
            'success_rate': success_rate
        }
    def _build_shortest_dist_matrix(self):
        """ä» PathDB æ„å»ºæœ€çŸ­è·ç¦»çŸ©é˜µ"""
        self.shortest_dist = np.full((self.n, self.n), 9999.0)
        np.fill_diagonal(self.shortest_dist, 0.0)

        if self.expert.path_db is None:
            logger.warning("PathDB not available, shortest_dist will use default values")
            return

        try:
            for i in range(self.n):
                for j in range(self.n):
                    if i == j:
                        continue
                    try:
                        cell = self.expert.path_db[i, j]
                        dist = float(cell['pathsdistance'][0][0])
                        self.shortest_dist[i, j] = dist
                    except:
                        pass
            logger.info("Successfully built shortest distance matrix from PathDB")
        except Exception as e:
            logger.warning(f"Failed to build shortest_dist from PathDB: {e}")

    def print_env_summary(self):
        """æ‰“å°ç¯å¢ƒç»Ÿè®¡æŒ‡æ ‡"""
        req_acc_rate = self.total_requests_accepted / max(1, self.total_requests_seen)
        dest_acc_rate = self.total_dest_accepted / max(1, self.total_dest_seen)
        logger.info("-" * 30)
        logger.info(f"ENV SUMMARY (t={self.t}/{self.T})")
        logger.info(
            f"Requests: Seen={self.total_requests_seen}, Acc={self.total_requests_accepted} ({req_acc_rate:.2%})")
        logger.info(f"Destinations: Seen={self.total_dest_seen}, Acc={self.total_dest_accepted} ({dest_acc_rate:.2%})")
        logger.info("-" * 30)

    def _clear_cache(self):
        """èµ„æºçŠ¶æ€æ”¹å˜æ—¶æ¸…ç©ºç¼“å­˜"""
        self._eval_cache.clear()

    def _get_network_state_dict(self) -> Dict:
        return {
            'bw': self.B, 'cpu': self.C, 'mem': self.M,
            'hvt': self.hvt_all, 'bw_ref_count': self.link_ref_count
        }

    def _get_flat_state(self) -> np.ndarray:
        net_state = self._get_network_state_dict()

        cpu_usage = (self.C_cap - net_state['cpu']) / max(1.0, self.C_cap)
        mem_usage = (self.M_cap - net_state['mem']) / max(1.0, self.M_cap)
        bw_usage = (self.B_cap - net_state['bw']) / max(1.0, self.B_cap)
        hvt_norm = np.clip(net_state['hvt'].flatten() / 10.0, 0, 1)

        req_vec = np.zeros(self.dim_request, dtype=np.float32)
        if self.current_request:
            req_vec[0] = self.current_request.get('bw_origin', 0.0) / max(1.0, self.B_cap)
            if self.current_request.get('cpu_origin') is not None:
                req_vec[1] = np.mean(self.current_request['cpu_origin']) / max(1.0, self.C_cap)
            if self.current_request.get('memory_origin') is not None:
                req_vec[2] = np.mean(self.current_request['memory_origin']) / max(1.0, self.M_cap)
            req_vec[3] = len(self.current_request.get('vnf', [])) / 8.0

            dests = self.current_request.get('dest', [])
            req_vec[4] = len(dests) / 10.0
            if len(dests) > 0:
                completed = len(dests) - len(self.unadded_dest_indices)
                req_vec[5] = completed / len(dests)

            dc_set = getattr(self.expert, 'DC', set())
            req_vec[6] = 1.0 if self.current_request.get('source') in dc_set else 0.0
            if self.nodes_on_tree:
                req_vec[7] = len(self.nodes_on_tree) / max(1, self.n)
            if self.current_tree:
                req_vec[8] = np.sum(self.current_tree['tree'] > 0) / max(1.0, self.L)
            req_vec[9] = len(self.unadded_dest_indices) / max(1, len(dests))

        flat_net = np.concatenate([cpu_usage, mem_usage, bw_usage, hvt_norm])
        final_state = np.zeros(self.STATE_VECTOR_SIZE, dtype=np.float32)
        final_state[:self.dim_network] = flat_net[:self.dim_network]
        final_state[self.dim_network:] = req_vec
        return final_state

    def _handle_leave_events(self, t: int):
        if t >= len(self.events):
            return
        leave_ids = self.events[t]['leave']
        if leave_ids.size == 0:
            return

        leave_set = set(leave_ids.tolist())
        remaining = []
        for req, tree in self.served_requests:
            if req['id'] in leave_set:
                bw_to_return = float(req.get('bw_origin', 0.0))
                # éå†æ ‘ä¸Šçš„æ¯æ¡é“¾è·¯
                for link_idx in np.where(tree['tree'] > 0)[0]:
                    if self.link_ref_count[link_idx] <= 0:
                        self.link_ref_count[link_idx] = 0

                    if self.link_ref_count[link_idx] > 0:
                        self.link_ref_count[link_idx] -= 1

                    if self.link_ref_count[link_idx] == 0:
                        self.B[link_idx] = min(self.B_cap, self.B[link_idx] + bw_to_return)

                # èŠ‚ç‚¹èµ„æºé‡Šæ”¾
                for node, vnf_t in np.argwhere(tree['hvt'] > 0):
                    if self.hvt_all[node, vnf_t] > 0:
                        self.hvt_all[node, vnf_t] -= 1
                        if self.hvt_all[node, vnf_t] == 0:
                            try:
                                j = req['vnf'].index(int(vnf_t + 1))
                                self.C[node] = min(self.C_cap, self.C[node] + req['cpu_origin'][j])
                                self.M[node] = min(self.M_cap, self.M[node] + req['memory_origin'][j])
                            except Exception:
                                pass
            else:
                remaining.append((req, tree))

        if len(self.served_requests) != len(remaining):
            self._clear_cache()
        self.served_requests = remaining

    def reset_request(self) -> Tuple[Optional[Dict], np.ndarray]:
        self._clear_cache()
        self.current_request = None
        while self.current_request is None and self.t < self.T:
            if self.t > 0:
                self._handle_leave_events(self.t - 1)
            if self.t >= len(self.events):
                self.t += 1
                continue
            arrive_ids = self.events[self.t]['arrive']
            self.t += 1
            if arrive_ids.size > 0:
                req_id = int(arrive_ids[0])
                if req_id in self.req_map:
                    self.current_request = self.req_map[req_id]

        if self.current_request is None:
            return None, self._get_flat_state()
        # ğŸ”¥ æ–°å¢: åˆå§‹åŒ–å¤šç›®æ ‡é›†åˆ
        self.destination_set = set(self.current_request.get('dest', []))
        self.served_destinations = set()
        self.vnf_sharing_map = {}

        self.total_requests_seen += 1
        self.total_dest_seen += len(self.current_request.get('dest', []))
        self.unadded_dest_indices = set(range(len(self.current_request.get('dest', []))))
        self.current_tree = {
            'id': self.current_request['id'],
            'tree': np.zeros(self.L),
            'hvt': np.zeros((self.n, self.K_vnf)),
            'paths_map': {}
        }
        self.nodes_on_tree = set([self.current_request['source']])
        self.path_manager.reset()

        # [ä¿®æ”¹] è°ƒç”¨æ­£ç¡®çš„ BackupPolicy æ¥å£ (set_tree -> set_current_tree)
        if self.current_request:
            self.backup_policy.set_current_request(self.current_request)
            self.backup_policy.set_current_tree(list(self.nodes_on_tree)) # åªä¼ èŠ‚ç‚¹åˆ—è¡¨ï¼Œä¸ä¼ {}
            # -----------------------------------------------------------
            # [æ–°å¢] 2. å¼€å§‹è®°å½•å½“å‰è¯·æ±‚
            # -----------------------------------------------------------
            # æå– VNF é“¾åç§° (ç¤ºä¾‹è½¬æ¢ï¼Œå¦‚æœä½ çš„ vnf æ˜¯æ•°å­—åˆ—è¡¨)
            vnf_chain_str = [f"VNF_{v}" for v in self.current_request.get('vnf', [])]

            self.metrics_logger.start_deployment(
                request_id=f"REQ_{self.current_request['id']}",
                vnf_chain=vnf_chain_str,
                destinations=self.current_request.get('dest', [])
            )
        # -----------------------------------------------------------
        # -----------------------------------------------------------
        # [æ–°å¢] 2. å¼€å§‹è®°å½•å½“å‰è¯·æ±‚
        # -----------------------------------------------------------
        # [ä¿®æ”¹] è°ƒç”¨ logger æ—¶ä¼ å…¥ t=self.t
        if hasattr(self, 'metrics_logger'):
            vnf_chain_str = [f"VNF_{v}" for v in self.current_request.get('vnf', [])]
            self.metrics_logger.start_deployment(
                request_id=f"REQ_{self.current_request['id']}",
                vnf_chain=vnf_chain_str,
                destinations=self.current_request.get('dest', []),
                t=self.t  # <--- [æ–°å¢] å¿…é¡»åŠ è¿™ä¸€è¡Œï¼Œç”¨äºæ—¶é—´è½´ç”»å›¾
            )

        return self.current_request, self._get_flat_state()
    def get_expert_high_level_candidates(self, state_vec: np.ndarray, top_k: int = 5) -> List[Tuple[int, float]]:
        if not self.current_request or not self.unadded_dest_indices:
            return []

        network_state = self._get_network_state_dict()
        network_state['request'] = self.current_request
        req_id = self.current_request['id']
        candidates: List[Tuple[int, float]] = []

        # Stage 1: S -> d
        if not self.current_tree['paths_map']:
            for d_idx in self.unadded_dest_indices:
                best_eval = -np.inf
                for k in range(1, self.K_path + 1):
                    cache_key = (req_id, d_idx, k)
                    if cache_key in self._eval_cache:
                        eval_val = self._eval_cache[cache_key]
                    else:
                        try:
                            eval_val, _, _, _, feasible, _, _, _ = self.expert._calc_eval(
                                self.current_request, d_idx, k, network_state
                            )
                            if not feasible or eval_val is None:
                                eval_val = -np.inf
                        except Exception as e:
                            logger.debug(f"_calc_eval failed for d={d_idx}, k={k}: {e}")
                            eval_val = -np.inf
                        self._eval_cache[cache_key] = eval_val

                    if eval_val > best_eval:
                        best_eval = eval_val
                if best_eval > -np.inf:
                    candidates.append((d_idx, float(best_eval)))

        # Stage 2: Tree -> d
        else:
            for d_idx in self.unadded_dest_indices:
                best_eval = -np.inf
                for conn_path in self.current_tree['paths_map'].values():
                    try:
                        _, eval_val, _, _ = self.expert._calc_atnp(
                            self.current_tree, conn_path, d_idx, network_state, self.nodes_on_tree
                        )
                        if eval_val is not None and eval_val > best_eval:
                            best_eval = eval_val
                    except Exception as e:
                        logger.debug(f"_calc_atnp failed for d={d_idx}: {e}")
                        continue
                if best_eval > -np.inf:
                    candidates.append((d_idx, float(best_eval)))

        # Fallback: ä½¿ç”¨æœ€çŸ­è·ç¦»
        if not candidates:
            fallback_cands = []
            source_node = self.current_request['source'] - 1
            dest_nodes = self.current_request['dest']

            for d_idx in self.unadded_dest_indices:
                try:
                    target_node = dest_nodes[d_idx] - 1
                    if 0 <= source_node < self.n and 0 <= target_node < self.n:
                        dist = float(self.shortest_dist[source_node, target_node])
                    else:
                        dist = 9999.0
                except:
                    dist = 9999.0
                fallback_cands.append((d_idx, -dist))

            fallback_cands.sort(key=lambda x: x[1], reverse=True)
            candidates = fallback_cands
            logger.debug(f"Using fallback strategy for request {req_id}")

        candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)

        if len(candidates_sorted) >= 2 and random.random() < self.expert_randomness:
            candidates_sorted[0], candidates_sorted[1] = candidates_sorted[1], candidates_sorted[0]

        limit = len(candidates_sorted) if top_k < 0 else min(top_k, len(candidates_sorted))
        return candidates_sorted[:max(1, limit)]

    def get_high_level_candidate_mask(self, candidates: List[Tuple[int, float]]) -> np.ndarray:
        mask = np.zeros(self.NB_HIGH_LEVEL_GOALS, dtype=np.float32)
        for d_idx, _ in candidates:
            if 0 <= d_idx < self.NB_HIGH_LEVEL_GOALS:
                mask[d_idx] = 1.0
        return mask

    def get_expert_high_level_goal(self, state_vec: np.ndarray) -> int:
        cands = self.get_expert_high_level_candidates(state_vec, top_k=1)
        if cands:
            return int(cands[0][0])
        if self.unadded_dest_indices:
            return int(next(iter(self.unadded_dest_indices)))
        return 0

    def get_expert_high_level_labels(self, state_vec: np.ndarray, top_k: int = 5) -> Tuple[List[int], List[float], int]:
        cands = self.get_expert_high_level_candidates(state_vec, top_k=top_k)
        if not cands:
            return [], [], 0
        ids = [int(c[0]) for c in cands]
        scores = [float(c[1]) for c in cands]
        return ids, scores, ids[0]

    def _get_path_for_i_idx(self, i_idx: int) -> List[int]:
        if not self.current_tree or not self.current_tree['paths_map']:
            return [self.current_request['source']] if self.current_request else [0]
        path = self.path_manager.get_path(i_idx)
        if path is None:
            if self.path_manager.paths:
                return self.path_manager.get_path(0)
            return [self.current_request['source']] if self.current_request else [0]
        return path

    def get_valid_low_level_actions(self) -> List[int]:
        valid_actions = []
        if not self.current_tree or not self.current_tree['paths_map']:
            for k in range(self.K_path):
                valid_actions.append(k)
        else:
            num_paths = max(1, len(self.path_manager))
            if len(self.path_manager) == 0:
                num_paths = len(self.current_tree['paths_map'])
            for i in range(num_paths):
                for k in range(self.K_path):
                    action_id = i * self.K_path + k
                    if action_id < self.NB_LOW_LEVEL_ACTIONS:
                        valid_actions.append(action_id)
        return valid_actions if valid_actions else [0]

    def get_low_level_action_mask(self) -> np.ndarray:
        mask = np.zeros(self.NB_LOW_LEVEL_ACTIONS, dtype=np.float32)
        for a in self.get_valid_low_level_actions():
            if 0 <= a < self.NB_LOW_LEVEL_ACTIONS:
                mask[a] = 1.0
        return mask

    def _decode_low_level_action(self, action: int) -> Tuple[int, int]:
        k_idx = int(action % self.K_path)
        i_idx = int(action // self.K_path)
        num_paths = max(1, len(self.path_manager))
        i_idx = i_idx % min(num_paths, self.MAX_PATHS_IN_TREE)
        return i_idx, k_idx

    def step_low_level(self, goal_dest_idx: int, low_level_action):
        """
        å¢å¼ºç‰ˆ step_low_level (All-in-One Integrated)ï¼š
        - æ ¸å¿ƒé€»è¾‘ï¼šExpert â†’ Backup â†’ Deployment
        - æ™ºèƒ½å¥–åŠ±ï¼šRewardCritic
        - æ•°æ®åŸ‹ç‚¹ï¼šè‡ªåŠ¨è®°å½•æ¯ä¸€æ­¥çš„èµ„æºæ¶ˆè€—ã€è·¯å¾„ã€å¤±è´¥åŸå› åˆ° VNFMetricsLogger
        - è§†è§‰è¯Šæ–­ï¼šä»…åœ¨å‡ºç°â€œéƒ¨åˆ†å¤±è´¥â€ï¼ˆPartial Failureï¼‰æ—¶è‡ªåŠ¨ä¿å­˜å¯è§†åŒ–å›¾åƒ
        - å…¨å±€ç»Ÿè®¡ï¼šæ›´æ–°å®Œå…¨/éƒ¨åˆ†æˆåŠŸç‡è®¡æ•°å™¨
        """
        self._clear_cache()

        # ---- è§£ç è¡ŒåŠ¨ ----
        if isinstance(low_level_action, tuple) and len(low_level_action) == 3:
            i_idx, k_idx, placement = low_level_action
        else:
            i_idx, k_idx = self._decode_low_level_action(int(low_level_action))
            placement = {}

        # [ç»Ÿè®¡] å¢åŠ å­ä»»åŠ¡è®¡æ•° (ç”¨äºè®¡ç®—éƒ¨åˆ†æˆåŠŸç‡)
        self.stats_total_subtasks += 1  # åŸæœ‰è®¡æ•°å™¨
        self.stats_sub_total += 1  # æ–°å¢è®¡æ•°å™¨ (Success Rate è®¡ç®—ç”¨)

        k = k_idx + 1

        # ---- æ— æ•ˆè¯·æ±‚ï¼šç›´æ¥ç»“æŸ ----
        if self.current_request is None or goal_dest_idx not in self.unadded_dest_indices:
            done = not (self.unadded_dest_indices and self.current_request)
            return self._get_flat_state(), 0.0, True, done

        # ---- ç½‘ç»œçŠ¶æ€å‡†å¤‡ ----
        network_state = self._get_network_state_dict()
        network_state['request'] = self.current_request

        # ---- æ‰§è¡Œè¿‡ç¨‹å˜é‡åˆå§‹åŒ– ----
        feasible = False
        plan = None
        backup_used = False
        backup_level = "primary"
        failure_reason = None

        # ===============================
        # 1) å°è¯• Expert è®¡ç®—
        # ===============================
        try:
            if not self.current_tree['paths_map']:
                # ç›´æ¥æ„é€ ç¬¬ä¸€æ¡è·¯å¾„
                eval_val, paths, tree, hvt, feasible, _, _, placement_expert = \
                    self.expert._calc_eval(self.current_request, goal_dest_idx, k, network_state)

                if feasible:
                    plan = {
                        'tree': tree,
                        'hvt': hvt,
                        'new_path_full': paths,
                        'feasible': True,
                        'placement': placement_expert
                    }

            else:
                conn_path = self._get_path_for_i_idx(i_idx)
                plan, eval_val, action, _ = self.expert._calc_atnp(
                    self.current_tree, conn_path, goal_dest_idx, network_state, self.nodes_on_tree
                )
                feasible = plan.get('feasible', False) if isinstance(plan, dict) else False

        except Exception as e:
            logger.warning(f"[Expert Error] goal={goal_dest_idx}, err={e}")
            feasible = False
            failure_reason = "invalid_action"

        # ===============================
        # 2) Expert å¤±è´¥ â†’ BackupPolicy
        # ===============================
        if not feasible:
            backup_used = True
            self.stats_backup_activated += 1

            # å°† numpy æ•°ç»„èµ„æºè½¬æˆ dictï¼ˆBackupPolicy éœ€è¦ï¼‰
            backup_net_state = network_state.copy()
            backup_net_state['cpu'] = {i: float(self.C[i]) for i in range(len(self.C))}
            backup_net_state['mem'] = {i: float(self.M[i]) for i in range(len(self.M))}

            self.backup_policy.set_current_tree(list(self.nodes_on_tree))
            plan = self.backup_policy.get_backup_plan(goal_dest_idx, backup_net_state)

            if plan and plan.get('feasible'):
                feasible = True
                self.stats_backup_succeeded += 1
                backup_level = plan.get("backup_type", "unknown")
            else:
                failure_reason = failure_reason or "resource_exhausted"

        # ===============================
        # 3) éƒ¨ç½²æˆ–å¤±è´¥å¤„ç†
        # ===============================
        if feasible and plan is not None:
            # ---- éƒ¨ç½²æˆåŠŸ ----
            self._apply_deployment(self.current_request, plan)

            # [ç»Ÿè®¡] å­ä»»åŠ¡æˆåŠŸæ•° +1
            self.stats_sub_success += 1

            if goal_dest_idx in self.unadded_dest_indices:
                self.unadded_dest_indices.remove(goal_dest_idx)

            # è®°å½•è·¯å¾„
            dest_list = self.current_request.get('dest', [])
            dest_node = dest_list[goal_dest_idx] if goal_dest_idx < len(dest_list) else None

            new_path = plan.get('new_path_full', [])
            if new_path:
                self.path_manager.add_path(new_path)
                if dest_node is not None:
                    self.current_tree['paths_map'][dest_node] = new_path
                self.nodes_on_tree.update(new_path)

            sub_task_done = True

            # è®¡ç®—åŸºç¡€ Cost
            path_len = len(new_path) if new_path else 1.0
            cost_val = 0.1 * (path_len / 10.0)

            # è‹¥æ‰€æœ‰ç›®çš„èŠ‚ç‚¹éƒ½å®Œæˆ
            if not self.unadded_dest_indices:
                if (self.current_request, self.current_tree) not in self.served_requests:
                    self.served_requests.append((self.current_request, self.current_tree))
                self.total_requests_accepted += 1

        else:
            # ---- å®Œå…¨å¤±è´¥ ----
            sub_task_done = False
            cost_val = 5.0
            failure_reason = failure_reason or "routing_deadlock"

            # [ç»Ÿè®¡] æ ‡è®°è¯¥è¯·æ±‚ä¸å†æ˜¯â€œå®Œç¾â€çš„
            self.current_req_is_perfect = False

            logger.debug(f"[Plan Failed] goal={goal_dest_idx}")

            # -----------------------------
            # [å¯è§†åŒ–] ä»…åœ¨éƒ¨åˆ†å¤±è´¥æ—¶ä¿å­˜å›¾åƒ
            # -----------------------------
            # å¦‚æœæ ‘ä¸­å·²ç»æœ‰è·¯å¾„(has_existing_paths=True)ï¼Œä½†å½“å‰è¿™ä¸€æ­¥å¤±è´¥äº†ï¼Œè¯´æ˜æ˜¯Partial Failure
            has_existing_paths = len(self.current_tree.get('paths_map', {})) > 0
            if self.enable_render and has_existing_paths:
                self.render_failure(
                    failed_dest_idx=goal_dest_idx,
                    title=f"Partial Failure: Req {self.current_request['id']} (Tree Exists)"
                )

        # ===============================
        # 4) QoSæ£€æŸ¥ + progress shaping
        # ===============================
        qos_viol = self._compute_qos_violation()
        progress = self._compute_progress(goal_dest_idx)

        # æ•´ä¸ªè¯·æ±‚æ˜¯å¦ç»ˆæ­¢
        request_done = not self.unadded_dest_indices

        # ===========================================================
        # [ä¿®æ”¹] 5. å‡†å¤‡è¯¦ç»†çš„ Logger æ•°æ® (é€‚é…æœ€ç»ˆç‰ˆ Logger)
        # ===========================================================

        # 1. å‡†å¤‡åŸºç¡€æ•°æ®
        dests = self.current_request.get('dest', [])
        dest_node_id = dests[goal_dest_idx] if goal_dest_idx < len(dests) else -1

        # 2. æ„å»ºè¯¦ç»†çš„èµ„æºä½¿ç”¨å­—å…¸ (ç”¨äº Logger å»é‡è®¡ç®—)
        vnf_placement_info = {}
        link_usage_info = {}

        step_cpu_cons = 0.0
        step_mem_cons = 0.0
        step_bw_cons = 0.0

        if feasible and plan:
            # --- æå– VNF æ”¾ç½®ä¿¡æ¯ ---
            # plan['placement'] é€šå¸¸æ˜¯ {vnf_index: node_id}
            # æˆ‘ä»¬éœ€è¦è½¬æˆ: {node_id: {'cpu': val, 'mem': val}}
            req_cpus = self.current_request.get('cpu_origin', [])
            req_mems = self.current_request.get('memory_origin', [])

            # å¦‚æœæœ‰ placement ä¿¡æ¯
            if 'placement' in plan:
                for v_idx, node in plan['placement'].items():
                    # è·å–è¯¥ VNF çš„å…·ä½“èµ„æºéœ€æ±‚
                    c_val = req_cpus[v_idx] if v_idx < len(req_cpus) else 0.0
                    m_val = req_mems[v_idx] if v_idx < len(req_mems) else 0.0

                    # è®°å½•åˆ°å­—å…¸ (å¦‚æœåŒä¸€ä¸ªèŠ‚ç‚¹æ”¾äº†å¤šä¸ªVNFï¼Œç´¯åŠ )
                    if node not in vnf_placement_info:
                        vnf_placement_info[node] = {'cpu': 0.0, 'mem': 0.0}
                    vnf_placement_info[node]['cpu'] += float(c_val)
                    vnf_placement_info[node]['mem'] += float(m_val)

                    # ç´¯è®¡æ€»æ¶ˆè€—
                    step_cpu_cons += c_val
                    step_mem_cons += m_val

            # --- æå–é“¾è·¯ä½¿ç”¨ä¿¡æ¯ ---
            path_nodes = plan.get('new_path_full', [])
            req_bw = float(self.current_request.get('bw_origin', 0.0))

            if len(path_nodes) > 1:
                for u, v in zip(path_nodes[:-1], path_nodes[1:]):
                    # ç¡®ä¿é“¾è·¯ key é¡ºåºä¸€è‡´ï¼Œä¾‹å¦‚æ€»æ˜¯å°å·åœ¨å‰ (u, v)
                    link_key = tuple(sorted((u, v)))
                    link_usage_info[link_key] = {'bw': float(req_bw)}

                # ç´¯è®¡æ€»æ¶ˆè€— (è·³æ•° * å¸¦å®½)
                step_bw_cons = req_bw * (len(path_nodes) - 1)

        # 3. ç»„è£… step_info
        step_info = {
            "destination": int(dest_node_id),
            "success": bool(feasible),
            "path": plan.get('new_path_full', []) if feasible and plan else [],
            "vnf_placement": vnf_placement_info,  # <--- [æ–°å¢] ä¼ å…¥æ”¾ç½®è¯¦æƒ…
            "link_usage": link_usage_info,  # <--- [æ–°å¢] ä¼ å…¥é“¾è·¯è¯¦æƒ…
            "backup_used": bool(backup_used),
            "backup_level": str(backup_level),
            "failure_reason": str(failure_reason) if not feasible else None
        }

        # 4. ç»„è£…æ¶ˆè€—æ¦‚è§ˆ (å…¼å®¹æ—§æ¥å£)
        resource_consumed = {
            "cpu": float(step_cpu_cons),
            "bw": float(step_bw_cons),
            "mem": float(step_mem_cons)
        }

        # 5. è·å–ç½‘ç»œçŠ¶æ€
        current_net_state = {
            "available_cpu": float(np.sum(self.C)),
            "available_bw": float(np.sum(self.B)),
            "available_mem": float(np.sum(self.M)),
            # ä¼ å…¥å®¹é‡ä»¥ä¾¿è®¡ç®—ç™¾åˆ†æ¯”
            "node_cpu_capacity": float(self.C_cap) if not isinstance(self.C_cap, (list, np.ndarray)) else float(
                np.mean(self.C_cap)),
            "node_mem_capacity": float(self.M_cap) if not isinstance(self.M_cap, (list, np.ndarray)) else float(
                np.mean(self.M_cap)),
            "link_bw_capacity": float(self.B_cap) if not isinstance(self.B_cap, (list, np.ndarray)) else float(
                np.mean(self.B_cap))
        }

        # D. å†™å…¥ Logger
        if hasattr(self, 'metrics_logger'):
            self.metrics_logger.record_step(step_info, resource_consumed, current_net_state)
        # ===============================
        # 6) è°ƒç”¨ RewardCritic (æ ¸å¿ƒ)
        # ===============================
        reward = self.reward_critic.criticize(
            sub_task_completed=sub_task_done,
            cost=cost_val,
            request_failed=(request_done and not sub_task_done),
            progress_to_goal=progress,
            backup_used=backup_used,
            backup_level=backup_level,
            qos_violations=qos_viol,
            failure_reason=failure_reason,
            agent_action=int(low_level_action) if not isinstance(low_level_action, tuple) else -1,
            expert_action=self.expert_low_level_action(goal_dest_idx),
            state_novelty=self._state_novelty(),
            expert_confidence=1.0
        )

        # ===============================
        # [Logger] 7) è¯·æ±‚ç»“æŸæ—¶çš„å¤„ç†
        # ===============================
        if request_done:
            # æ›´æ–°ç»Ÿè®¡è®¡æ•°å™¨
            self.stats_req_total += 1
            if self.current_req_is_perfect:
                self.stats_req_perfect += 1

            # é€šçŸ¥ Logger ç»“æŸéƒ¨ç½²è®°å½•
            if hasattr(self, 'metrics_logger'):
                self.metrics_logger.end_deployment(current_net_state)

                # (å¯é€‰) å®æ—¶ç›‘æ§æ‰“å°ï¼šæ¯10ä¸ªè¯·æ±‚æ‰“å°ä¸€æ¬¡æœ€è¿‘çš„æˆåŠŸç‡
                if self.stats_req_total % 10 == 0:
                    realtime_stats = self.metrics_logger.get_realtime_stats()
                    acc = realtime_stats.get('recent_full_acceptance', 0)
                    logger.info(f"[Metrics] Recent Full Acceptance: {acc:.2%}")

        return self._get_flat_state(), float(reward), sub_task_done, request_done


    def _apply_deployment(self, request: Dict, plan: Dict):
        """åº”ç”¨éƒ¨ç½²æ–¹æ¡ˆåˆ°ç½‘ç»œçŠ¶æ€ï¼ˆå¸¦é˜²å¾¡æ€§æ£€æŸ¥ï¼‰"""
        tree_branch = plan.get('tree', np.zeros(self.L))
        hvt_branch = plan.get('hvt', np.zeros((self.n, self.K_vnf)))
        self.current_tree['tree'] = np.logical_or(self.current_tree['tree'], tree_branch).astype(float)

        bw_req = float(request.get('bw_origin', 0.0))

        # é“¾è·¯èµ„æºæ‰£é™¤ï¼šå½“å¼•ç”¨è®¡æ•°ä¸º0æ—¶æ‰çœŸæ­£æ‰£å¸¦å®½ï¼Œç„¶åæ— è®ºå¦‚ä½•å¼•ç”¨è®¡æ•°+1
        for link_idx in np.where(tree_branch > 0)[0]:
            if self.link_ref_count[link_idx] == 0:
                # é˜²å¾¡æ€§ï¼šä¸è¦æŠŠå¸¦å®½æ‰£åˆ°è´Ÿå€¼
                new_bw = self.B[link_idx] - bw_req
                self.B[link_idx] = max(0.0, new_bw)
            self.link_ref_count[link_idx] += 1

        # èŠ‚ç‚¹èµ„æºæ‰£é™¤ï¼ˆä¿æŒåŸæœ‰è¯­ä¹‰ï¼‰
        for node, vnf_t in np.argwhere(hvt_branch > 0):
            if self.hvt_all[node, vnf_t] == 0:
                try:
                    j = request['vnf'].index(int(vnf_t + 1))
                    self.C[node] = max(0.0, self.C[node] - request['cpu_origin'][j])
                    self.M[node] = max(0.0, self.M[node] - request['memory_origin'][j])
                except Exception:
                    pass
            self.hvt_all[node, vnf_t] += 1

        self.current_tree['hvt'] = np.maximum(self.current_tree['hvt'], hvt_branch)

    def _shortest_distance(self, src: int, dst: int) -> float:
        """è·å–ä¸¤èŠ‚ç‚¹é—´çš„æœ€çŸ­è·ç¦»"""
        if src == dst:
            return 0.0

        # ä½¿ç”¨é¢„è®¡ç®—çš„çŸ©é˜µ
        if hasattr(self, 'shortest_dist'):
            src_idx = src - 1 if src > 0 else 0
            dst_idx = dst - 1 if dst > 0 else 0
            if 0 <= src_idx < self.n and 0 <= dst_idx < self.n:
                return float(self.shortest_dist[src_idx, dst_idx])

        return 9999.0

    def _find_closest_tree_node_to_goal(self, goal_node: int) -> int:
        """æ‰¾åˆ°æ ‘ä¸­ç¦»ç›®æ ‡æœ€è¿‘çš„èŠ‚ç‚¹"""
        if not self.nodes_on_tree:
            return self.current_request.get('source', 1)

        min_dist = float('inf')
        closest_node = list(self.nodes_on_tree)[0]

        for node in self.nodes_on_tree:
            dist = self._shortest_distance(node, goal_node)
            if dist < min_dist:
                min_dist = dist
                closest_node = node

        return closest_node
    def _compute_progress(self, goal_idx):
        """
        ä¿®å¤ç‰ˆ progress è®¡ç®—

        è®¡ç®—å½“å‰çŠ¶æ€è·ç¦»ç›®æ ‡çš„æ”¹å–„ç¨‹åº¦ï¼ŒèŒƒå›´ [-1,1]
        - è´Ÿæ•° = ç¦»ç›®æ ‡æ›´è¿œ
        - æ­£æ•° = æ›´æ¥è¿‘ç›®æ ‡

        ä½¿ç”¨æœ€çŸ­è·¯å¾„çŸ©é˜µè€Œä¸æ˜¯ networkxï¼ˆé¿å…ä¾èµ–é—®é¢˜ï¼‰
        """
        try:
            if not self.current_request:
                return 0.0

            dest_list = self.current_request.get('dest', [])
            if goal_idx >= len(dest_list):
                return 0.0

            goal_node = dest_list[goal_idx]

            # è·å–å½“å‰ä½ç½®ï¼ˆæ ‘ä¸­æœ€è¿‘æ·»åŠ çš„èŠ‚ç‚¹ï¼‰
            if self.nodes_on_tree:
                # æ‰¾åˆ°æ ‘ä¸­ç¦»ç›®æ ‡æœ€è¿‘çš„èŠ‚ç‚¹
                current_node = self._find_closest_tree_node_to_goal(goal_node)
            else:
                current_node = self.current_request.get('source', 1)

            # ä½¿ç”¨é¢„è®¡ç®—çš„æœ€çŸ­è·¯å¾„çŸ©é˜µ
            current_dist = self._shortest_distance(current_node, goal_node)

            # è·å–ä¸Šä¸€æ­¥çš„è·ç¦»
            prev_dist = getattr(self, "_prev_dist", current_dist)
            self._prev_dist = current_dist

            # å¦‚æœç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œè¿”å›0
            if prev_dist == current_dist and not hasattr(self, "_progress_initialized"):
                self._progress_initialized = True
                return 0.0

            # è®¡ç®—è¿›åº¦
            if prev_dist == 0:
                return 1.0 if current_dist == 0 else -1.0

            progress = (prev_dist - current_dist) / max(1, prev_dist)
            return float(np.clip(progress, -1.0, 1.0))

        except Exception as e:
            logger.debug(f"[_compute_progress] Error: {e}")
            return 0

    def _compute_qos_violation(self):
        """
        ç®€æ˜“ QoS è¿åæ£€æµ‹ï¼š
        è¿”å›å½¢å¦‚ {"delay":0.2, "bandwidth":0.1}
        æ‰€æœ‰å€¼ âˆˆ [0,1]ï¼Œè¡¨ç¤ºè¿åæ¯”ä¾‹
        """
        viol = {}

        # ---- å»¶è¿Ÿè¿å ----
        if hasattr(self, "current_delay") and hasattr(self, "delay_threshold"):
            if self.current_delay > self.delay_threshold:
                viol["delay"] = min(1.0, (self.current_delay - self.delay_threshold) / self.delay_threshold)

        # ---- å¸¦å®½è¿å ----
        if hasattr(self, "current_bw_usage") and hasattr(self, "bw_threshold"):
            if self.current_bw_usage > self.bw_threshold:
                viol["bandwidth"] = min(1.0, (self.current_bw_usage - self.bw_threshold) / self.bw_threshold)

        # ---- ä¸¢åŒ…ç‡è¿å ----
        if hasattr(self, "current_loss") and hasattr(self, "loss_threshold"):
            if self.current_loss > self.loss_threshold:
                viol["packet_loss"] = min(1.0, (self.current_loss - self.loss_threshold) / self.loss_threshold)

        return viol if viol else None

    def _compute_progress(self, goal_dest_idx):
        """
        progress âˆˆ [-1,1]
        è´Ÿæ•° = ç¦»ç›®æ ‡æ›´è¿œ
        æ­£æ•° = æ›´æ¥è¿‘ç›®æ ‡
        """
        try:
            dest_node = self.current_request["dest"][goal_dest_idx]
            current_node = self.current_state_info.get("current_node", None)

            if current_node is None or dest_node is None:
                return 0.0

            # ä½¿ç”¨æœ€çŸ­è·¯å¾„è·ç¦»è¡¡é‡è¿›åº¦
            import networkx as nx
            d_prev = nx.shortest_path_length(self.G, self.prev_node, dest_node) if hasattr(self, "prev_node") else None
            d_now = nx.shortest_path_length(self.G, current_node, dest_node)

            self.prev_node = current_node

            if d_prev is None:
                return 0.0

            progress = (d_prev - d_now) / max(1, d_prev)
            return float(np.clip(progress, -1.0, 1.0))

        except:
            return 0.0

    def expert_low_level_action(self, goal_dest_idx):
        """
        è¿”å›ä¸“å®¶æ¨èçš„ä½å±‚åŠ¨ä½œ
        è‹¥æ— æ³•è·å¾—ä¸“å®¶åŠ¨ä½œï¼Œåˆ™è¿”å› -1ï¼ˆè¡¨ç¤ºè·³è¿‡DAggerå¥–åŠ±ï¼‰
        """
        try:
            return self.expert_last_action  # å¦‚æœä½ åœ¨ expert è°ƒç”¨åä¿å­˜
        except:
            return -1

    def _state_novelty(self):
        """
        ç”¨äºåˆ¤æ–­å½“å‰çŠ¶æ€æ˜¯å¦â€œæ–°é¢–â€
        å€¼è¶Šå¤§ï¼ˆæ¥è¿‘1ï¼‰è¡¨ç¤ºè¿™ä¸ªçŠ¶æ€å¾ˆå°‘è¢«è®¿é—®è¿‡â†’é¼“åŠ±æ¢ç´¢
        """
        if not hasattr(self, "state_visit_counter"):
            self.state_visit_counter = {}

        s = tuple(self._get_flat_state().astype(int))

        if s not in self.state_visit_counter:
            self.state_visit_counter[s] = 0
        self.state_visit_counter[s] += 1

        # visit è¶Šå°‘ â†’ æ–°é¢–åº¦è¶Šé«˜
        novelty = 1.0 / np.sqrt(self.state_visit_counter[s])
        return float(np.clip(novelty, 0.0, 1.0))

    # [æ–°å¢] è¾…åŠ©æ–¹æ³•ï¼šå‡†å¤‡æ•°æ®å¹¶è°ƒç”¨ç”»å›¾
    def render_failure(self, failed_dest_idx, failed_path=None, title="Failure"):
        if not self.enable_render or not self.current_request:
            return

        # å‡†å¤‡æ•°æ®
        src = self.current_request['source']
        dests = self.current_request.get('dest', [])
        failed_node = dests[failed_dest_idx] if failed_dest_idx < len(dests) else -1

        success_paths = self.current_tree.get('paths_map', {})

        vnf_placement = {}
        if self.current_tree:
            ns, vs = np.where(self.current_tree['hvt'] > 0)
            for n, v in zip(ns, vs):
                vnf_placement[f"VNF_{v}"] = n

        # -----------------------------
        # [æ ¸å¿ƒ] ç”Ÿæˆæ–‡ä»¶åå¹¶è°ƒç”¨ä¿å­˜
        # -----------------------------
        # æ–‡ä»¶åæ ¼å¼: fail_req{è¯·æ±‚ID}_goal{ç›®æ ‡ç´¢å¼•}_node{ç›®æ ‡èŠ‚ç‚¹å·}.png
        req_id = self.current_request.get('id', self.total_requests_seen)
        filename = f"fail_req{req_id}_goal{failed_dest_idx}_node{failed_node}.png"

        # æ‹¼æ¥å®Œæ•´è·¯å¾„
        full_path = os.path.join(self.failure_output_dir, filename)

        self.visualizer.draw_failure_case(
            src=src,
            dests=dests,
            success_paths=success_paths,
            vnf_placement=vnf_placement,
            failed_dest=failed_node,
            failed_path=failed_path,
            title=title,
            save_path=full_path  # <--- ä¼ å…¥è·¯å¾„
        )

        # ========== ä¿®æ”¹3: VNFå…±äº«æ£€æŸ¥ (æ–°å¢æ–¹æ³•) ==========
        def can_share_vnf(self, node_id: int, vnf_type: int, dest_idx: int) -> bool:
            """
            æ£€æŸ¥ç›®æ ‡dest_idxæ˜¯å¦å¯ä»¥å…±äº«èŠ‚ç‚¹node_idä¸Šçš„vnf_typeå®ä¾‹

            Args:
                node_id: èŠ‚ç‚¹ID (1-based)
                vnf_type: VNFç±»å‹ (0-based)
                dest_idx: ç›®æ ‡ç´¢å¼• (0-based)

            Returns:
                True if å¯ä»¥å…±äº«
            """
            key = (node_id, vnf_type)

            # å¦‚æœè¯¥ä½ç½®æ²¡æœ‰VNFå®ä¾‹,ä¸èƒ½å…±äº«
            node_idx = node_id - 1
            if self.hvt_all[node_idx, vnf_type] == 0:
                return False

            # æ£€æŸ¥èµ„æºæ˜¯å¦å……è¶³ (ç®€åŒ–ç‰ˆ,å®é™…éœ€è¦æ›´å¤æ‚çš„é€»è¾‘)
            # è¿™é‡Œå‡è®¾æ¯ä¸ªVNFå®ä¾‹å¯ä»¥æœåŠ¡æœ€å¤š3ä¸ªç›®æ ‡
            if key in self.vnf_sharing_map:
                return len(self.vnf_sharing_map[key]) < 3

            return True

        def share_vnf(self, node_id: int, vnf_type: int, dest_idx: int):
            """è®°å½•VNFå…±äº«"""
            key = (node_id, vnf_type)
            if key not in self.vnf_sharing_map:
                self.vnf_sharing_map[key] = set()
            self.vnf_sharing_map[key].add(dest_idx)

        def get_vnf_sharing_rate(self) -> float:
            """
            è®¡ç®—å½“å‰è¯·æ±‚çš„VNFå…±äº«ç‡

            Returns:
                å…±äº«ç‡ âˆˆ [0, 1]
            """
            if not self.vnf_sharing_map:
                return 0.0

            total_vnf_instances = sum(len(dests) for dests in self.vnf_sharing_map.values())
            unique_vnf_instances = len(self.vnf_sharing_map)

            if total_vnf_instances == 0:
                return 0.0

            # å…±äº«ç‡ = 1 - (ç‹¬ç«‹å®ä¾‹æ•° / æ€»éœ€æ±‚æ•°)
            return 1.0 - (unique_vnf_instances / total_vnf_instances)