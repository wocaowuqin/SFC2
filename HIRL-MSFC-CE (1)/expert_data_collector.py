#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
expert_data_collector.py
ä¸“å®¶æ•°æ®æ”¶é›†å™¨

åŠŸèƒ½:
1. ä½¿ç”¨ç¯å¢ƒå†…ç½®çš„ä¸“å®¶ç³»ç»Ÿæ”¶é›†é«˜è´¨é‡è½¨è¿¹
2. è‡ªåŠ¨è¿‡æ»¤ä½è´¨é‡æ•°æ®
3. ä¿å­˜ä¸ºpickleæ ¼å¼ä¾›åç»­ä½¿ç”¨
"""
from typing import List, Dict, Optional  # è®°å¾—å¯¼å…¥ Optional
import os
import pickle
import logging
from pathlib import Path
from typing import List, Dict, Any, Tuple
import numpy as np
import torch
from collections import defaultdict

logger = logging.getLogger(__name__)


class ExpertDataCollector:
    """ä¸“å®¶æ•°æ®æ”¶é›†å™¨"""

    def __init__(self, env, output_dir: Path):
        """
        Args:
            env: SFC_HIRL_Env_GNN ç¯å¢ƒå®ä¾‹
            output_dir: æ•°æ®ä¿å­˜ç›®å½•
        """
        self.env = env
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ•°æ®ç»Ÿè®¡
        self.stats = {
            'total_episodes': 0,
            'successful_episodes': 0,
            'total_transitions': 0,
            'high_confidence_transitions': 0,
            'low_confidence_transitions': 0,
            'failed_episodes': 0
        }

    def collect(self, num_episodes: int = 1000,
                min_confidence: float = 0.5,
                save_interval: int = 100) -> List[Dict]:
        """
        æ”¶é›†ä¸“å®¶æ¼”ç¤ºæ•°æ®

        Args:
            num_episodes: æ”¶é›†çš„episodeæ•°é‡
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆè¿‡æ»¤ä½è´¨é‡æ•°æ®ï¼‰
            save_interval: æ¯éš”å¤šå°‘episodeä¿å­˜ä¸€æ¬¡

        Returns:
            expert_buffer: ä¸“å®¶è½¨è¿¹åˆ—è¡¨
        """
        logger.info("=" * 60)
        logger.info("é˜¶æ®µ1: æ”¶é›†ä¸“å®¶æ¼”ç¤ºæ•°æ®")
        logger.info("=" * 60)
        logger.info(f"ç›®æ ‡episodes: {num_episodes}")
        logger.info(f"æœ€å°ç½®ä¿¡åº¦: {min_confidence}")

        expert_buffer = []
        episode_count = 0

        while episode_count < num_episodes:
            # æ”¶é›†ä¸€ä¸ªepisodeçš„æ•°æ®
            episode_data = self._collect_episode(min_confidence)

            if episode_data is not None:
                expert_buffer.extend(episode_data)
                self.stats['successful_episodes'] += 1
                self.stats['total_transitions'] += len(episode_data)

                logger.info(f"Episode {episode_count + 1}/{num_episodes}: "
                            f"æ”¶é›†äº† {len(episode_data)} ä¸ªtransitions")
            else:
                self.stats['failed_episodes'] += 1
                logger.debug(f"Episode {episode_count + 1}: ä¸“å®¶å¤±è´¥ï¼Œè·³è¿‡")

            episode_count += 1
            self.stats['total_episodes'] = episode_count

            # å®šæœŸä¿å­˜
            if episode_count % save_interval == 0:
                self._save_buffer(expert_buffer, f"expert_data_ep{episode_count}.pkl")
                self._print_stats()

        # æœ€ç»ˆä¿å­˜
        self._save_buffer(expert_buffer, "expert_data_final.pkl")
        self._print_stats()

        logger.info(f"âœ… ä¸“å®¶æ•°æ®æ”¶é›†å®Œæˆ: {len(expert_buffer)} transitions")
        return expert_buffer

    def _collect_episode(self, min_confidence: float) -> Optional[List[Dict]]:
        """
        æ”¶é›†å•ä¸ªepisodeçš„ä¸“å®¶æ•°æ®

        Returns:
            episode_data: è¯¥episodeçš„æ‰€æœ‰transitionsï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        episode_data = []

        # é‡ç½®ç¯å¢ƒ
        current_request, state = self.env.reset_request()
        if current_request is None:
            return None

        req_id = current_request.get('id', 'unknown')

        # Episodeå¾ªç¯
        while len(self.env.unadded_dest_indices) > 0:
            # === ä½¿ç”¨ä¸“å®¶é€‰æ‹©ç›®æ ‡ ===
            flat_state = self.env._get_flat_state()
            expert_candidates = self.env.get_expert_high_level_candidates(
                flat_state, top_k=5
            )

            if not expert_candidates:
                # ä¸“å®¶æ— æ³•å¤„ç†ï¼Œæ”¾å¼ƒè¿™ä¸ªepisode
                logger.debug(f"Req {req_id}: ä¸“å®¶æ— æ³•æä¾›ç›®æ ‡å€™é€‰")
                return None

            # é€‰æ‹©ä¸“å®¶æœ€æ¨èçš„ç›®æ ‡
            expert_goal, expert_goal_score = expert_candidates[0]

            # ç½®ä¿¡åº¦è¿‡æ»¤
            if expert_goal_score < min_confidence:
                logger.debug(f"Req {req_id}: ä¸“å®¶ç½®ä¿¡åº¦è¿‡ä½ ({expert_goal_score:.3f})")
                return None

            # === è·å–æœ‰æ•ˆåŠ¨ä½œ ===
            valid_actions = self.env.get_valid_low_level_actions()
            if not valid_actions:
                logger.debug(f"Req {req_id}: æ²¡æœ‰æœ‰æ•ˆåŠ¨ä½œ")
                return None

            # === è®°å½•å½“å‰çŠ¶æ€ï¼ˆæ‰§è¡Œå‰ï¼‰ ===
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦æ‰¾å‡ºä¸“å®¶å®é™…ä¼šé€‰æ‹©çš„åŠ¨ä½œ
            # ç­–ç•¥ï¼šè®©ç¯å¢ƒæ‰§è¡Œï¼Œç„¶åä»æ—¥å¿—/è¿”å›å€¼ä¸­æå–ä¸“å®¶åŠ¨ä½œ

            # ä¿å­˜çŠ¶æ€ç”¨äºåç»­æ„å»ºtransition
            current_state = state
            current_goal = expert_goal

            # === å°è¯•æ‰€æœ‰æœ‰æ•ˆåŠ¨ä½œï¼Œæ‰¾å‡ºä¸“å®¶å®é™…é€‰æ‹©çš„åŠ¨ä½œ ===
            # è¿™æ˜¯ä¸€ä¸ªæŠ€å·§ï¼šæˆ‘ä»¬é€šè¿‡ç¯å¢ƒçš„stepæ¥è·çŸ¥ä¸“å®¶é€‰æ‹©
            expert_action = self._infer_expert_action(
                current_goal, valid_actions
            )

            if expert_action is None or expert_action not in valid_actions:
                # æ— æ³•æ¨æ–­ä¸“å®¶åŠ¨ä½œ
                logger.debug(f"Req {req_id}: æ— æ³•æ¨æ–­ä¸“å®¶åŠ¨ä½œ")
                return None

            # === æ‰§è¡Œä¸“å®¶åŠ¨ä½œ ===
            next_state, reward, sub_done, req_done = self.env.step_low_level(
                current_goal, expert_action
            )

            # === æ„å»ºtransition ===
            transition = {
                'state': current_state,  # GNNçŠ¶æ€ (x, ei, ea, req)
                'goal': current_goal,  # ç›®æ ‡èŠ‚ç‚¹ç´¢å¼•
                'action': expert_action,  # ä¸“å®¶é€‰æ‹©çš„åŠ¨ä½œ
                'next_state': next_state,  # ä¸‹ä¸€ä¸ªçŠ¶æ€
                'reward': reward,  # å¥–åŠ±
                'done': req_done,  # æ˜¯å¦ç»“æŸ
                'valid_actions': valid_actions,  # æœ‰æ•ˆåŠ¨ä½œåˆ—è¡¨
                'expert_confidence': expert_goal_score,  # ä¸“å®¶ç½®ä¿¡åº¦
                'request_id': req_id  # è¯·æ±‚ID
            }

            # æ ‡è®°ç½®ä¿¡åº¦
            if expert_goal_score >= 0.8:
                self.stats['high_confidence_transitions'] += 1
            else:
                self.stats['low_confidence_transitions'] += 1

            episode_data.append(transition)

            # æ›´æ–°çŠ¶æ€
            state = next_state

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if req_done:
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸï¼ˆæ‰€æœ‰ç›®æ ‡éƒ½å®Œæˆï¼‰
                if len(self.env.unadded_dest_indices) == 0:
                    # æˆåŠŸå®Œæˆï¼Œè¿”å›æ•°æ®
                    return episode_data
                else:
                    # éƒ¨åˆ†å®Œæˆæˆ–å¤±è´¥
                    logger.debug(f"Req {req_id}: æœªèƒ½å®Œæˆæ‰€æœ‰ç›®æ ‡")
                    return None

        # æ­£å¸¸å®Œæˆ
        return episode_data if len(self.env.unadded_dest_indices) == 0 else None

    def _infer_expert_action(self, goal: int, valid_actions: List[int]) -> Optional[int]:
        """
        æ¨æ–­ä¸“å®¶ä¼šé€‰æ‹©çš„åŠ¨ä½œï¼ˆä½¿ç”¨MSFCE_Solverä¸“å®¶ç³»ç»Ÿï¼‰

        ç­–ç•¥ï¼š
        1. è°ƒç”¨ç¯å¢ƒçš„ä¸“å®¶æ–¹æ³•è·å–æœ€ä¼˜åŠ¨ä½œ
        2. å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨å¯å‘å¼ç­–ç•¥

        Args:
            goal: ç›®æ ‡èŠ‚ç‚¹
            valid_actions: æœ‰æ•ˆåŠ¨ä½œåˆ—è¡¨

        Returns:
            expert_action: ä¸“å®¶é€‰æ‹©çš„åŠ¨ä½œç´¢å¼•ï¼Œå¦‚æœæ— æ³•æ¨æ–­åˆ™è¿”å›None
        """
        # æ–¹æ³•1: ä½¿ç”¨ç¯å¢ƒå†…ç½®çš„ä¸“å®¶æ–¹æ³•
        try:
            # ç¯å¢ƒå·²ç»æœ‰ expert_low_level_action æ–¹æ³•
            expert_action = self.env.expert_low_level_action(goal)
            if expert_action is not None and expert_action in valid_actions:
                return expert_action
        except Exception as e:
            logger.debug(f"Failed to get expert action: {e}")

        # æ–¹æ³•2: ä½¿ç”¨ä¸“å®¶ç³»ç»Ÿçš„_calc_evalæ–¹æ³•
        # è¿™æ˜¯MSFCE_Solverçš„æ ¸å¿ƒè¯„ä¼°æ–¹æ³•
        try:
            network_state = self.env._get_flat_state()
            best_action = None
            best_eval = -float('inf')

            # è¯„ä¼°æ¯ä¸ªæœ‰æ•ˆåŠ¨ä½œ
            for action in valid_actions[:5]:  # é™åˆ¶è¯„ä¼°æ•°é‡ï¼Œé¿å…å¤ªæ…¢
                # è§£æåŠ¨ä½œåˆ°(p_idx, k_idx)
                # æ ¹æ®ä½ çš„åŠ¨ä½œç©ºé—´å®šä¹‰æ¥è§£æ
                p_idx = action // self.env.K_path
                k_idx = action % self.env.K_path
                k = k_idx + 1  # 1-based

                try:
                    # è°ƒç”¨ä¸“å®¶çš„è¯„ä¼°å‡½æ•°
                    eval_val, paths, tree, hvt, feasible, _, _, _ = \
                        self.env.expert._calc_eval(
                            self.env.current_request,
                            goal,
                            k,
                            network_state
                        )

                    if feasible and eval_val > best_eval:
                        best_eval = eval_val
                        best_action = action
                except:
                    continue

            if best_action is not None:
                return best_action
        except Exception as e:
            logger.debug(f"Expert evaluation failed: {e}")

        # æ–¹æ³•3: å¯å‘å¼ - é€‰æ‹©ç¬¬ä¸€ä¸ªæœ‰æ•ˆåŠ¨ä½œ
        if valid_actions:
            return valid_actions[0]

        return None

    def _save_buffer(self, buffer: List[Dict], filename: str):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        filepath = self.output_dir / filename

        with open(filepath, 'wb') as f:
            pickle.dump({
                'buffer': buffer,
                'stats': self.stats,
                'env_config': {
                    'n_nodes': self.env.n,
                    'n_links': self.env.L,
                    'n_vnf_types': self.env.K_vnf,
                    'n_actions': self.env.NB_LOW_LEVEL_ACTIONS,
                    'n_goals': self.env.NB_HIGH_LEVEL_GOALS
                }
            }, f)

        logger.info(f"ğŸ’¾ å·²ä¿å­˜æ•°æ®åˆ°: {filepath}")

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("\n" + "=" * 60)
        logger.info("ä¸“å®¶æ•°æ®æ”¶é›†ç»Ÿè®¡")
        logger.info("=" * 60)
        logger.info(f"æ€»episodes:          {self.stats['total_episodes']}")
        logger.info(f"æˆåŠŸepisodes:        {self.stats['successful_episodes']}")
        logger.info(f"å¤±è´¥episodes:        {self.stats['failed_episodes']}")
        logger.info(f"æ€»transitions:       {self.stats['total_transitions']}")
        logger.info(f"é«˜ç½®ä¿¡åº¦:           {self.stats['high_confidence_transitions']}")
        logger.info(f"ä½ç½®ä¿¡åº¦:           {self.stats['low_confidence_transitions']}")

        if self.stats['total_episodes'] > 0:
            success_rate = (self.stats['successful_episodes'] /
                            self.stats['total_episodes']) * 100
            logger.info(f"æˆåŠŸç‡:             {success_rate:.2f}%")

        logger.info("=" * 60 + "\n")

    @staticmethod
    def load_expert_data(filepath: Path) -> Tuple[List[Dict], Dict]:
        """
        åŠ è½½ä¸“å®¶æ•°æ®

        Returns:
            buffer: ä¸“å®¶è½¨è¿¹åˆ—è¡¨
            metadata: å…ƒæ•°æ®ï¼ˆç»Ÿè®¡ä¿¡æ¯ã€ç¯å¢ƒé…ç½®ç­‰ï¼‰
        """
        with open(filepath, 'rb') as f:
            data = pickle.load(f)

        logger.info(f"âœ… å·²åŠ è½½ä¸“å®¶æ•°æ®: {len(data['buffer'])} transitions")
        return data['buffer'], data


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================
if __name__ == "__main__":
    import hyperparameters as H
    from hirl_sfc_env_gnn import SFC_HIRL_Env_GNN

    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # åˆå§‹åŒ–ç¯å¢ƒ
    env = SFC_HIRL_Env_GNN(
        input_dir=H.INPUT_DIR,
        topo=H.TOPOLOGY_MATRIX,
        dc_nodes=H.DC_NODES,
        capacities=H.CAPACITIES,
        use_gnn=True
    )

    # åˆ›å»ºæ”¶é›†å™¨
    collector = ExpertDataCollector(env, output_dir=H.OUTPUT_DIR / "expert_data")

    # æ”¶é›†æ•°æ®
    expert_buffer = collector.collect(
        num_episodes=1000,
        min_confidence=0.5,
        save_interval=100
    )

    print(f"\nâœ… æ”¶é›†å®Œæˆ: {len(expert_buffer)} ä¸ªé«˜è´¨é‡transitions")