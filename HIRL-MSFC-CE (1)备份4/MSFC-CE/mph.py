# mph.py (ä¿®æ­£ç‰ˆ)
import numpy as np
import scipy.io as sio
import os
import time
import config

from mph_strategy import serve_request_mph
from serve_leave_request import serve_leave_request


class Request:
    def __init__(self, data):
        keys = data.dtype.names
        self.id = data['id'][0][0]
        self.source = int(data['source'][0][0]) - 1
        if 'dests' in keys:
            raw_dest = data['dests'][0]
        elif 'dest' in keys:
            raw_dest = data['dest'][0]
        else:
            raw_dest = np.array([])
        self.dest = [int(x) - 1 for x in raw_dest.flatten()]
        if 'vnfs' in keys:
            raw_vnf = data['vnfs'][0]
        elif 'vnf' in keys:
            raw_vnf = data['vnf'][0]
        else:
            raw_vnf = np.array([1, 2, 3])
        self.vnf = [int(x) - 1 for x in raw_vnf.flatten()]
        self.bw_origin = float(data['bw_origin'][0][0]) if 'bw_origin' in keys else 50.0
        if 'cpu_origin' in keys:
            self.cpu_origin = data['cpu_origin'][0].flatten()
        else:
            self.cpu_origin = np.ones(len(self.vnf)) * 100.0
        if 'memory_origin' in keys:
            self.memory_origin = data['memory_origin'][0].flatten()
        else:
            self.memory_origin = np.ones(len(self.vnf)) * 200.0
        self.arrive_time_step = int(data['arrive_time_step'][0][0]) if 'arrive_time_step' in keys else 0
        self.leave_time_step = int(data['leave_time_step'][0][0]) if 'leave_time_step' in keys else 100
        if 'arrive_time' in keys: self.arrive_time_step = int(data['arrive_time'][0][0])
        if 'leave_time' in keys: self.leave_time_step = int(data['leave_time'][0][0])


print("=" * 60)
print("MPH ç­–ç•¥ä»¿çœŸ")
print("=" * 60)

# ========== é…ç½®æ£€æŸ¥ ==========
print("\n[1] é…ç½®æ£€æŸ¥:")
print(f"  èŠ‚ç‚¹æ•°: {config.node_num}")
print(f"  é“¾è·¯æ•°: {config.link_num}")
print(f"  DCèŠ‚ç‚¹æ•°: {len(config.DC)}")
print(f"  DCèŠ‚ç‚¹: {config.DC}")
print(f"  CPUå®¹é‡: {config.cpu_capacity}")
print(f"  MEMå®¹é‡: {config.memory_capacity}")
print(f"  BWå®¹é‡: {config.bandwidth_capacity}")

# ========== åŠ è½½æ•°æ® ==========
print("\n[2] åŠ è½½æ•°æ®...")
try:
    path_data = sio.loadmat(os.path.join(config.DATA_PATH, 'US_Backbone_paths.mat'))
    config.path = path_data['Paths']
    print(f"  âœ“ è·¯å¾„æ•°æ®: shape={config.path.shape}")

    req_data = sio.loadmat(os.path.join(config.DATA_PATH, 'sorted_requests.mat'))
    req_key = 'sorted_requests' if 'sorted_requests' in req_data else 'requests'
    requests_list = [Request(r) for r in req_data[req_key].flatten()]
    print(f"  âœ“ è¯·æ±‚æ•°æ®: {len(requests_list)} ä¸ªè¯·æ±‚")

    event_data = sio.loadmat(os.path.join(config.DATA_PATH, 'event_list.mat'))
    event_list = event_data['event_list'].flatten()
    print(f"  âœ“ äº‹ä»¶æ•°æ®: {len(event_list)} ä¸ªæ—¶é—´æ­¥")

except Exception as e:
    print(f"  âœ— åŠ è½½å¤±è´¥: {e}")
    exit()

# ========== è¯·æ±‚æ ·æœ¬æ£€æŸ¥ ==========
print("\n[3] è¯·æ±‚æ ·æœ¬æ£€æŸ¥ (å‰3ä¸ª):")
for i, req in enumerate(requests_list[:3]):
    print(f"  Request {req.id}:")
    print(f"    Source: {req.source}, Dests: {req.dest}")
    print(f"    VNFs: {req.vnf}, BW: {req.bw_origin}")
    print(f"    CPU: {req.cpu_origin}, MEM: {req.memory_origin}")

# ========== åˆå§‹åŒ– ==========
T = min(400, len(event_list))
Bandwidth_status = np.full((T, config.link_num), config.bandwidth_capacity, dtype=float)
CPU_status = np.full((T, config.node_num), config.cpu_capacity, dtype=float)
Memory_status = np.full((T, config.node_num), config.memory_capacity, dtype=float)
hvt_all = np.zeros((config.node_num, config.type_num), dtype=int)

blocking_rate = np.zeros(T)
block_flag = 0
arrival_request_num = 0
served_records = []

# ========== æ ¸å¿ƒä»¿çœŸ ==========
print("\n[4] å¼€å§‹ä»¿çœŸ...")
start_time = time.time()

# ğŸ”¥ è°ƒè¯•æ¨¡å¼ï¼šåªå¤„ç†å‰5ä¸ªè¯·æ±‚
DEBUG_MODE = True
debug_count = 0
MAX_DEBUG = 5

for t in range(T):
    if (t + 1) % 50 == 0:
        rate = block_flag / arrival_request_num if arrival_request_num else 0
        print(f"\n=== Time {t + 1} ===")
        print(f"  Requests: {arrival_request_num}, Blocked: {block_flag}, Rate: {rate:.4f}")

    # ç»§æ‰¿ä¸Šä¸€æ—¶åˆ»çŠ¶æ€
    if t > 0:
        Bandwidth_status[t] = Bandwidth_status[t - 1].copy()
        CPU_status[t] = CPU_status[t - 1].copy()
        Memory_status[t] = Memory_status[t - 1].copy()

    curr_event = event_list[t]

    # å¤„ç†ç¦»å¼€äº‹ä»¶
    try:
        raw_leave = curr_event['leave_event']
        l_ids = raw_leave.flatten().tolist() if raw_leave.size > 0 else []
    except:
        l_ids = []

    if l_ids:
        rem = []
        for rec in served_records:
            if rec['id'] in l_ids:
                Bandwidth_status[t], CPU_status[t], Memory_status[t], hvt_all = \
                    serve_leave_request(rec['req'], rec['tree'], Bandwidth_status[t],
                                      CPU_status[t], Memory_status[t], hvt_all)
            else:
                rem.append(rec)
        served_records = rem

    # å¤„ç†åˆ°è¾¾äº‹ä»¶
    try:
        raw_arrive = curr_event['arrive_event']
        a_ids = raw_arrive.flatten().tolist() if raw_arrive.size > 0 else []
    except:
        a_ids = []

    for rid in a_ids:
        req = next((r for r in requests_list if r.id == rid), None)
        if req:
            arrival_request_num += 1

            # ğŸ”¥ åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¯¦ç»†è¾“å‡º
            if DEBUG_MODE and debug_count < MAX_DEBUG:
                print(f"\n{'='*60}")
                print(f"[DEBUG {debug_count+1}/{MAX_DEBUG}] Request {req.id} at t={t}")
                print(f"{'='*60}")

            # ğŸ”¥ è°ƒç”¨MPHç­–ç•¥
            req_updated, bw_status, cpu_status, mem_status, hvt_all_updated, \
                res_req, res_tree, bw_consumed, cpu_consumed, mem_consumed, success = \
                serve_request_mph(req.id, req, Bandwidth_status[t], CPU_status[t],
                                Memory_status[t], hvt_all,
                                config.node_num, config.link_num, config.type_num)

            if DEBUG_MODE and debug_count < MAX_DEBUG:
                if success:
                    print(f"\nâœ“ SUCCESS!")
                    print(f"  Resources consumed: BW={bw_consumed:.2f}, CPU={cpu_consumed:.2f}, MEM={mem_consumed:.2f}")
                    print(f"  Tree links used: {np.sum(res_tree > 0)}")
                else:
                    print(f"\nâœ— BLOCKED!")
                debug_count += 1

            if success:
                # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æ›´æ–°åçš„èµ„æºçŠ¶æ€
                served_records.append({'id': req.id, 'req': res_req, 'tree': res_tree})
                Bandwidth_status[t] = bw_status
                CPU_status[t] = cpu_status
                Memory_status[t] = mem_status
                hvt_all = hvt_all_updated
            else:
                block_flag += 1

    if arrival_request_num > 0:
        blocking_rate[t] = block_flag / arrival_request_num

    # ğŸ”¥ è°ƒè¯•æ¨¡å¼ï¼šå¤„ç†å®Œå‰5ä¸ªè¯·æ±‚åæå‰é€€å‡º
    if DEBUG_MODE and debug_count >= MAX_DEBUG:
        print(f"\n[DEBUG] Processed {MAX_DEBUG} requests, exiting early...")
        break

end_time = time.time()
print(f"\n{'='*60}")
print(f"ä»¿çœŸå®Œæˆ")
print(f"{'='*60}")
print(f"è€—æ—¶: {end_time - start_time:.2f}s")
print(f"æ€»è¯·æ±‚: {arrival_request_num}")
print(f"æˆåŠŸ: {arrival_request_num - block_flag}")
print(f"é˜»å¡: {block_flag}")
print(f"æœ€ç»ˆé˜»å¡ç‡: {blocking_rate[t]:.4f}")

# ä¿å­˜ç»“æœ
output_dir = 'output'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
sio.savemat(os.path.join(output_dir, 'mph_blocking_rate.mat'), {'blocking_rate': blocking_rate})
print(f"\nç»“æœå·²ä¿å­˜åˆ° {output_dir}/mph_blocking_rate.mat")