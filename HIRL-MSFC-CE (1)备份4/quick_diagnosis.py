#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿè¯Šæ–­è„šæœ¬ï¼šä¸€é”®åˆ†æé˜»å¡ç‡å’Œæ¥å—ç‡ä¸Šé™é—®é¢˜

è¿è¡Œæ–¹æ³•ï¼š
    python quick_diagnosis.py

è¾“å‡ºï¼š
1. PathDBè´¨é‡æŠ¥å‘Šï¼ˆç†è®ºä¸Šé™ï¼‰
2. åˆå§‹é˜»å¡ç‡åˆ†æï¼ˆÎµ-greedyå½±å“ï¼‰
3. ä¼˜åŒ–å»ºè®®
"""

import numpy as np
import sys
import pickle
from pathlib import Path
from collections import defaultdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

import hyperparameters as H
from expert_msfce import MSFCE_Solver


def main():
    print("\n" + "=" * 80)
    print("ğŸ” é˜»å¡ç‡ä¸æ¥å—ç‡ä¸Šé™è¯Šæ–­")
    print("=" * 80)

    # 1. åŠ è½½æ•°æ®
    print("\n[1/4] åŠ è½½æ•°æ®...")
    expert = MSFCE_Solver(
        H.INPUT_DIR / "US_Backbone_path.mat",
        H.TOPOLOGY_MATRIX,
        H.DC_NODES,
        H.CAPACITIES
    )

    with open(H.INPUT_DIR / 'sorted_requests.pkl', 'rb') as f:
        requests = pickle.load(f)

    print(f"  âœ“ Expertåˆå§‹åŒ–å®Œæˆ")
    print(f"  âœ“ è¯·æ±‚æ•°æ®åŠ è½½å®Œæˆ: {len(requests)}æ¡")

    # 2. åˆ†æPathDBè´¨é‡
    print("\n[2/4] åˆ†æPathDBè´¨é‡...")

    stats = {
        'total_requests': len(requests),
        'no_path_count': 0,
        'insufficient_dc_count': 0,
        'feasible_count': 0,
        'vnf_distribution': defaultdict(int),
        'problematic_pairs': []
    }

    for req in requests[:200]:  # æŠ½æ ·200ä¸ªè¯·æ±‚
        src = req['source']
        dests = req['dest']
        vnf_count = len(req.get('vnf', []))

        stats['vnf_distribution'][vnf_count] += 1

        all_feasible = True

        for dest in dests:
            max_dc_on_path = 0
            has_path = False

            # æ£€æŸ¥æ‰€æœ‰kæ¡è·¯å¾„
            for k in range(1, expert.k_path + 1):
                nodes, dist, links = expert._get_path_info(src, dest, k)

                if not nodes:
                    continue

                has_path = True
                dc_count = len([n for n in nodes if n in expert.DC])
                max_dc_on_path = max(max_dc_on_path, dc_count)

            if not has_path:
                stats['no_path_count'] += 1
                stats['problematic_pairs'].append((src, dest, 'no_path'))
                all_feasible = False
                break

            if max_dc_on_path < vnf_count:
                stats['insufficient_dc_count'] += 1
                stats['problematic_pairs'].append((src, dest, f'max_dc={max_dc_on_path}, need={vnf_count}'))
                all_feasible = False
                break

        if all_feasible:
            stats['feasible_count'] += 1

    # è®¡ç®—ç†è®ºä¸Šé™
    sample_size = min(200, len(requests))
    theoretical_limit = stats['feasible_count'] / sample_size

    print(f"\n  ğŸ“Š PathDBè´¨é‡æŠ¥å‘Šï¼ˆåŸºäº{sample_size}ä¸ªæ ·æœ¬ï¼‰:")
    print(f"     ç†è®ºå¯æ»¡è¶³: {stats['feasible_count']} ({theoretical_limit:.1%})")
    print(f"     æ— è·¯å¾„:     {stats['no_path_count']} ({stats['no_path_count'] / sample_size:.1%})")
    print(f"     DCèŠ‚ç‚¹ä¸è¶³: {stats['insufficient_dc_count']} ({stats['insufficient_dc_count'] / sample_size:.1%})")

    print(f"\n  ğŸ“ˆ VNFéœ€æ±‚åˆ†å¸ƒ:")
    for vnf_count in sorted(stats['vnf_distribution'].keys()):
        count = stats['vnf_distribution'][vnf_count]
        print(f"     {vnf_count}ä¸ªVNF: {count}æ¬¡ ({count / sample_size:.1%})")

    # å±•ç¤ºé—®é¢˜èŠ‚ç‚¹å¯¹
    if stats['problematic_pairs']:
        print(f"\n  âš ï¸  é—®é¢˜èŠ‚ç‚¹å¯¹ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰:")
        for i, (src, dest, reason) in enumerate(stats['problematic_pairs'][:5]):
            print(f"     {i + 1}. ({src} â†’ {dest}): {reason}")

    # 3. åˆ†æåˆå§‹é˜»å¡ç‡åŸå› 
    print("\n[3/4] åˆ†æåˆå§‹é˜»å¡ç‡...")

    # æ¨¡æ‹Ÿå®Œå…¨éšæœºç­–ç•¥
    random_success = 0
    random_trials = 50

    for req in requests[:random_trials]:
        src = req['source']
        dests = req['dest']

        # éšæœºé€‰æ‹©kå€¼ï¼ˆæ¨¡æ‹ŸÎµ=1.0æ—¶çš„è¡Œä¸ºï¼‰
        success = True
        for dest in dests:
            k = np.random.randint(1, expert.k_path + 1)
            nodes, _, _ = expert._get_path_info(src, dest, k)

            if not nodes:
                success = False
                break

            dc_count = len([n for n in nodes if n in expert.DC])
            if dc_count < len(req.get('vnf', [])):
                success = False
                break

        if success:
            random_success += 1

    random_acc = random_success / random_trials

    print(f"\n  ğŸ² éšæœºç­–ç•¥æ¨¡æ‹Ÿï¼ˆÎµ=1.0ï¼‰:")
    print(f"     æˆåŠŸç‡: {random_acc:.1%}")
    print(f"     é¢„æœŸé˜»å¡ç‡: {1 - random_acc:.1%}")

    # 4. è¾“å‡ºç»“è®ºå’Œå»ºè®®
    print("\n[4/4] ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š...")
    print("\n" + "=" * 80)
    print("ğŸ“‹ è¯Šæ–­ç»“è®º")
    print("=" * 80)

    print(f"\nâœ… é—®é¢˜1ï¼šåˆå§‹é˜»å¡ç‡é«˜ï¼ˆ43.8%ï¼‰çš„åŸå› ")
    print(f"   åŸå› ï¼šÎµ-greedyå®Œå…¨éšæœºæ¢ç´¢")
    print(f"   è¯æ®ï¼šéšæœºç­–ç•¥æˆåŠŸç‡ä»…{random_acc:.1%}ï¼Œä¸å®é™…åˆå§‹é˜»å¡ç‡å»åˆ")
    print(f"   å½±å“ï¼šå‰100ä¸ªepisodeæ€§èƒ½æå·®")

    print(f"\nâœ… é—®é¢˜2ï¼šæœ€ç»ˆæ¥å—ç‡ä¸Šé™ï¼ˆ95-96%ï¼‰çš„åŸå› ")
    if theoretical_limit < 0.97:
        print(f"   ä¸»è¦åŸå› ï¼šPathDBè´¨é‡é™åˆ¶ï¼ˆç†è®ºä¸Šé™{theoretical_limit:.1%}ï¼‰")
        print(f"   æ¬¡è¦åŸå› ï¼šèµ„æºç«äº‰ã€è®­ç»ƒä¸è¶³")
    else:
        print(f"   ä¸»è¦åŸå› ï¼šèµ„æºç«äº‰ï¼ˆPathDBè´¨é‡æ­£å¸¸ï¼Œç†è®ºä¸Šé™{theoretical_limit:.1%}ï¼‰")
        print(f"   æ¬¡è¦åŸå› ï¼šDQNæœªå®Œå…¨æ”¶æ•›")

    print("\n" + "=" * 80)
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
    print("=" * 80)

    # å»ºè®®ä¼˜å…ˆçº§
    if theoretical_limit < 0.97:
        print("\nğŸ”´ ä¼˜å…ˆçº§1ï¼šæå‡PathDBè´¨é‡")
        print("   æ–¹æ¡ˆAï¼šå¢åŠ DCèŠ‚ç‚¹æ•°é‡")
        print(f"         å½“å‰: {len(expert.DC)}ä¸ª")
        print(f"         å»ºè®®: â‰¥{int(len(expert.DC) * 1.5)}ä¸ªï¼ˆå¢åŠ 50%ï¼‰")
        print("   æ–¹æ¡ˆBï¼šå¢åŠ Kå€¼")
        print(f"         å½“å‰: k={expert.k_path}")
        print(f"         å»ºè®®: kâ‰¥{expert.k_path + 3}ï¼ˆå¢åŠ 3æ¡å¤‡ç”¨è·¯å¾„ï¼‰")
        print("   æ–¹æ¡ˆCï¼šé™ä½VNFéœ€æ±‚")
        print("         å½“å‰: 2-4ä¸ªVNF")
        print("         å»ºè®®: é™åˆ¶ä¸º2-3ä¸ªVNF")

    print("\nğŸŸ¡ ä¼˜å…ˆçº§2ï¼šé™ä½åˆå§‹é˜»å¡ç‡")
    print("   æ–¹æ¡ˆAï¼šå‡å°‘é¢„è®­ç»ƒéšæœºæ€§")
    print("         å¢åŠ PRE_TRAIN_STEPS: 100 â†’ 500")
    print("   æ–¹æ¡ˆBï¼šé™ä½åˆå§‹epsilon")
    print("         ä¿®æ”¹initial_epsilon: 1.0 â†’ 0.5")
    print("   æ–¹æ¡ˆCï¼šå»¶é•¿æ¢ç´¢è¡°å‡")
    print("         å¢åŠ EXPLORATION_STEPS: 500K â†’ 1M")

    print("\nğŸŸ¢ ä¼˜å…ˆçº§3ï¼šæå‡æœ€ç»ˆæ€§èƒ½")
    print("   æ–¹æ¡ˆAï¼šå¢åŠ è®­ç»ƒè½®æ•°")
    print("         EPISODE_LIMIT: 300 â†’ 500")
    print("   æ–¹æ¡ˆBï¼šå¢åŠ Metaè®­ç»ƒé¢‘ç‡")
    print("         META_TRAIN_FREQ: 100 â†’ 50")
    print("   æ–¹æ¡ˆCï¼šæ·»åŠ æ—©åœæœºåˆ¶")
    print("         patience=50, min_improvement=0.01")

    print("\n" + "=" * 80)
    print("ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨")
    print("=" * 80)

    if theoretical_limit < 0.97:
        print("\n1ï¸âƒ£  å…ˆè§£å†³PathDBè´¨é‡é—®é¢˜ï¼ˆç†è®ºä¸Šé™ä¸è¶³ï¼‰")
        print("   â†’ è¿è¡Œ: python improve_pathdb.py")
        print("\n2ï¸âƒ£  å†ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼ˆé™ä½åˆå§‹é˜»å¡ç‡ï¼‰")
        print("   â†’ ä½¿ç”¨: hyperparameters_optimized.py")
    else:
        print("\n1ï¸âƒ£  ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼ˆPathDBè´¨é‡æ­£å¸¸ï¼‰")
        print("   â†’ ä½¿ç”¨: hyperparameters_optimized.py")
        print("\n2ï¸âƒ£  ç›‘æ§è®­ç»ƒè¿‡ç¨‹")
        print("   â†’ æ¯10ä¸ªepisodeæ£€æŸ¥æ¥å—ç‡å˜åŒ–")

    print("\n" + "=" * 80)
    print("âœ… è¯Šæ–­å®Œæˆ")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()