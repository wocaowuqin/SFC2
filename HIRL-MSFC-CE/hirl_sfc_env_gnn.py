#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
hirl_sfc_env_gnn.py - Multicast-Aware Version
å¤šæ’­æ„ŸçŸ¥å›¾ç¥ç»ç½‘ç»œç¯å¢ƒ
"""
import logging
import numpy as np
import torch
from gym import spaces
from typing import Dict, List, Tuple, Optional, Any, Set

from hirl_sfc_env import SFC_HIRL_Env

logger = logging.getLogger(__name__)


class SFC_HIRL_Env_GNN(SFC_HIRL_Env):
    """
    å¤šæ’­æ„ŸçŸ¥GNNç¯å¢ƒ

    åˆ›æ–°ç‚¹:
    1. å¤šç›®æ ‡é›†åˆç¼–ç  (Set Transformerè¾“å…¥)
    2. VNFå…±äº«çŠ¶æ€ç‰¹å¾ (å…±äº«æ½œåŠ›é¢„æµ‹)
    3. è¯·æ±‚å‘é‡å¢å¼º (å¤šç›®æ ‡ä¿¡æ¯)
    4. åŠ¨æ€å›¾æ›´æ–° (æ ‘ç»“æ„æ¼”åŒ–)
    """

    def __init__(self, input_dir, topo, dc_nodes, capacities, use_gnn=True):
        # 1. è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(input_dir, topo, dc_nodes, capacities)

        self.use_gnn = use_gnn
        self.topo = topo

        if self.use_gnn:
            self._build_edge_index()

            # ===== ç‰¹å¾ç»´åº¦å®šä¹‰ =====
            # ğŸ”¥ å¢å¼ºèŠ‚ç‚¹ç‰¹å¾
            # åŸæœ‰: [CPU, Mem, DC, Src, Dst, InTree] + VNF_OneHot
            # æ–°å¢: [NumDestNearby, AvgDistToDests, VNFSharingPotential]
            self.node_feat_dim = 6 + self.K_vnf + 3  # 9 + K_vnf

            # ğŸ”¥ å¢å¼ºè¾¹ç‰¹å¾
            # åŸæœ‰: [BW, InTree, Hop]
            # æ–°å¢: [SharedByDests, AvgTraffic]
            self.edge_feat_dim = 3 + 2  # 5

            # ğŸ”¥ å¢å¼ºè¯·æ±‚å‘é‡
            # åŸæœ‰: åŸºç¡€è¯·æ±‚ç‰¹å¾
            # æ–°å¢: [NumDests, AvgBW, SharingStrategy, DestSetEncoding...]
            self.request_dim = 10 + 4 + self.NB_HIGH_LEVEL_GOALS  # åŠ¨æ€é•¿åº¦

            # è¦†ç›– Observation Space
            self.observation_space = spaces.Box(
                low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32
            )

            # ===== å¤šæ’­ä¸“ç”¨ç¼“å­˜ =====
            self._dest_dist_cache: Dict[int, np.ndarray] = {}

        logger.info(f"SFC_HIRL_Env_GNN initialized (Multicast Mode). "
                    f"Node feat: {self.node_feat_dim}, Edge feat: {self.edge_feat_dim}, "
                    f"Request dim: {self.request_dim}")

    def _build_edge_index(self):
        """
        æ„å»ºedge_index (å®Œå…¨ä¿ç•™åŸé€»è¾‘)
        """
        rows, cols = np.where(self.topo > 0)
        self.link_id_to_edge_idx = {}

        use_expert_map = hasattr(self.expert, 'link_map')
        edge_list = []

        for idx, (u, v) in enumerate(zip(rows, cols)):
            edge_list.append([u, v])

            phys_id = -1
            if use_expert_map:
                phys_id = self.expert.link_map.get((u + 1, v + 1))
                if phys_id is None:
                    phys_id = self.expert.link_map.get((v + 1, u + 1))

            if phys_id is not None and phys_id > 0:
                self.link_id_to_edge_idx[phys_id - 1] = idx
            elif not use_expert_map:
                if idx < self.L:
                    self.link_id_to_edge_idx[idx] = idx

        self.edge_index = torch.tensor(np.array(edge_list).T, dtype=torch.long)
        self.edge_hops = torch.tensor(
            [float(self.topo[u, v]) for u, v in zip(rows, cols)],
            dtype=torch.float32
        )

        logger.info(f"GNN Graph built: {self.edge_index.shape[1]} edges.")

    def _compute_dest_distances(self, dest_set: Set[int]) -> np.ndarray:
        """
        è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹åˆ°ç›®æ ‡é›†åˆçš„å¹³å‡è·ç¦»

        Args:
            dest_set: ç›®æ ‡èŠ‚ç‚¹é›†åˆ (1-based)

        Returns:
            avg_dist: [n] æ¯ä¸ªèŠ‚ç‚¹åˆ°ç›®æ ‡é›†åˆçš„å¹³å‡è·ç¦»
        """
        cache_key = frozenset(dest_set)
        if cache_key in self._dest_dist_cache:
            return self._dest_dist_cache[cache_key]

        avg_dist = np.zeros(self.n)

        if not dest_set:
            return avg_dist

        for i in range(self.n):
            dists = []
            for dest in dest_set:
                dest_idx = dest - 1
                if 0 <= dest_idx < self.n:
                    dists.append(self.shortest_dist[i, dest_idx])

            avg_dist[i] = np.mean(dists) if dists else 999.0

        self._dest_dist_cache[cache_key] = avg_dist
        return avg_dist

    def _compute_vnf_sharing_potential(self, dest_set: Set[int]) -> np.ndarray:
        """
        è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„VNFå…±äº«æ½œåŠ›

        æ½œåŠ›å…¬å¼:
            potential[i] = Î± * (1 - avg_dist[i] / max_dist)
                         + Î² * (avail_cpu[i] / max_cpu)
                         + Î³ * num_nearby_dests[i]

        Args:
            dest_set: ç›®æ ‡èŠ‚ç‚¹é›†åˆ (1-based)

        Returns:
            potential: [n] æ¯ä¸ªèŠ‚ç‚¹çš„å…±äº«æ½œåŠ›åˆ†æ•° âˆˆ [0, 1]
        """
        # 1. è·ç¦»å› å­
        avg_dist = self._compute_dest_distances(dest_set)
        max_dist = np.max(avg_dist) if np.max(avg_dist) > 0 else 1.0
        dist_factor = 1.0 - avg_dist / max_dist

        # 2. èµ„æºå› å­
        cpu_util = self.C / max(1, self.C_cap)
        resource_factor = 1.0 - cpu_util

        # 3. é‚»è¿‘ç›®æ ‡æ•°é‡
        nearby_count = np.zeros(self.n)
        for i in range(self.n):
            for dest in dest_set:
                dest_idx = dest - 1
                if 0 <= dest_idx < self.n:
                    if self.shortest_dist[i, dest_idx] <= 3:  # 3è·³å†…
                        nearby_count[i] += 1

        max_count = np.max(nearby_count) if np.max(nearby_count) > 0 else 1.0
        neighbor_factor = nearby_count / max_count

        # 4. åŠ æƒç»„åˆ
        alpha, beta, gamma = 0.4, 0.3, 0.3
        potential = alpha * dist_factor + beta * resource_factor + gamma * neighbor_factor

        # å½’ä¸€åŒ–åˆ° [0, 1]
        potential = np.clip(potential, 0, 1)

        return potential

    def _get_graph_state(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ç”Ÿæˆå¤šæ’­æ„ŸçŸ¥çš„å›¾çŠ¶æ€ (å®Œæ•´ä¿®å¤ç‰ˆ)

        ä¿®å¤:
        - Line 251-252: paths_map å€¼ç±»å‹æ£€æŸ¥
        - æ·»åŠ è¯¦ç»†æ—¥å¿—ç”¨äºè°ƒè¯•

        Returns:
            x: [n, node_feat_dim] èŠ‚ç‚¹ç‰¹å¾
            edge_index: [2, E] è¾¹ç´¢å¼•
            edge_attr: [E, edge_feat_dim] è¾¹ç‰¹å¾
            request_vec: [request_dim] è¯·æ±‚å‘é‡
        """
        if not self.current_request:
            # ç©ºè¯·æ±‚: è¿”å›é›¶å¼ é‡
            x = torch.zeros((self.n, self.node_feat_dim))
            edge_attr = torch.zeros((self.edge_index.shape[1], self.edge_feat_dim))
            request_vec = torch.zeros(self.request_dim)
            return x, self.edge_index, edge_attr, request_vec

        # ===== 1. èŠ‚ç‚¹ç‰¹å¾ [n, 9 + K_vnf] =====
        src = self.current_request['source']
        dest_set = set(self.current_request.get('dest', []))
        tree_set = self.nodes_on_tree

        # è®¡ç®—è¾…åŠ©ç‰¹å¾
        avg_dist = self._compute_dest_distances(dest_set)
        sharing_potential = self._compute_vnf_sharing_potential(dest_set)

        node_feats = []
        for i in range(self.n):
            nid = i + 1

            # åŸºç¡€ç‰¹å¾ (6ç»´)
            feat = [
                1.0 - self.C[i] / max(1, self.C_cap),  # CPUåˆ©ç”¨ç‡
                1.0 - self.M[i] / max(1, self.M_cap),  # Memåˆ©ç”¨ç‡
                1.0 if nid in self.expert.DC else 0.0,  # æ˜¯å¦DC
                1.0 if nid == src else 0.0,  # æ˜¯å¦æºèŠ‚ç‚¹
                1.0 if nid in dest_set else 0.0,  # æ˜¯å¦ç›®æ ‡èŠ‚ç‚¹
                1.0 if nid in tree_set else 0.0  # æ˜¯å¦åœ¨æ ‘ä¸Š
            ]

            # ğŸ”¥ å¤šæ’­å¢å¼ºç‰¹å¾ (3ç»´)
            num_nearby = sum(1 for d in dest_set
                             if 0 <= d - 1 < self.n and self.shortest_dist[i, d - 1] <= 3)
            feat.extend([
                num_nearby / max(1, len(dest_set)),  # å½’ä¸€åŒ–é‚»è¿‘ç›®æ ‡æ•°
                1.0 - avg_dist[i] / max(1, np.max(avg_dist)),  # å½’ä¸€åŒ–å¹³å‡è·ç¦»
                sharing_potential[i]  # VNFå…±äº«æ½œåŠ›
            ])

            # VNFçŠ¶æ€ (K_vnfç»´)
            feat.extend((self.hvt_all[i] / 10.0).tolist())

            node_feats.append(feat)

        x = torch.tensor(node_feats, dtype=torch.float32)

        # ===== 2. è¾¹ç‰¹å¾ [E, 5] - ğŸ”§ ä¿®å¤ç‰ˆ =====
        num_edges = self.edge_index.shape[1]
        edge_attrs = torch.zeros((num_edges, self.edge_feat_dim), dtype=torch.float32)

        tree_links = self.current_tree.get('tree', np.zeros(self.L)) if self.current_tree else np.zeros(self.L)

        for phys_idx in range(self.L):
            if phys_idx not in self.link_id_to_edge_idx:
                continue

            edge_idx = self.link_id_to_edge_idx[phys_idx]

            # åŸºç¡€ç‰¹å¾ (3ç»´)
            bw_util = 1.0 - self.B[phys_idx] / max(1, self.B_cap)
            in_tree = 1.0 if tree_links[phys_idx] > 0 else 0.0
            hop = self.edge_hops[edge_idx].item()

            # ===== ğŸ”¥ ä¿®å¤: è®¡ç®—å…±äº«ç‡ =====
            shared_by = 0

            try:
                if self.current_tree and 'paths_map' in self.current_tree:
                    paths_map = self.current_tree['paths_map']

                    if not isinstance(paths_map, dict):
                        logger.warning(f"paths_map is not dict: {type(paths_map)}")
                    else:
                        for dest_key, path_info in paths_map.items():
                            links_list = None

                            # ğŸ”§ å…³é”®ä¿®å¤: å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„
                            if isinstance(path_info, dict):
                                # æƒ…å†µ1: {'path': [...], 'links': [...], ...}
                                links_list = path_info.get('links', [])

                            elif isinstance(path_info, list):
                                # æƒ…å†µ2: ç›´æ¥æ˜¯é“¾è·¯åˆ—è¡¨ [link1, link2, ...]
                                links_list = path_info

                            elif isinstance(path_info, (tuple, set)):
                                # æƒ…å†µ3: tuple/set å½¢å¼
                                links_list = list(path_info)

                            else:
                                # æƒ…å†µ4: æœªçŸ¥ç±»å‹,è®°å½•è­¦å‘Š
                                logger.debug(f"Unknown path_info type: {type(path_info)} for dest {dest_key}")
                                continue

                            # æ£€æŸ¥å½“å‰é“¾è·¯æ˜¯å¦åœ¨è¿™æ¡è·¯å¾„ä¸­
                            if links_list is not None and phys_idx in links_list:
                                shared_by += 1

            except Exception as e:
                # é˜²å¾¡æ€§: å³ä½¿å‡ºé”™ä¹Ÿä¸å½±å“å…¶ä»–ç‰¹å¾
                logger.debug(f"Error computing shared_by for link {phys_idx}: {e}")
                shared_by = 0

            # å½’ä¸€åŒ–å…±äº«ç‡
            shared_rate = shared_by / max(1, len(dest_set)) if dest_set else 0.0

            # å¹³å‡æµé‡ (ç®€åŒ–ç‰ˆ: ä½¿ç”¨å¸¦å®½åˆ©ç”¨ç‡)
            avg_traffic = bw_util

            edge_attrs[edge_idx] = torch.tensor([
                bw_util, in_tree, hop, shared_rate, avg_traffic
            ])

        # ===== 3. è¯·æ±‚å‘é‡ [request_dim] =====
        # å¤ç”¨çˆ¶ç±»çš„æ‰å¹³çŠ¶æ€ä½œä¸ºåŸºç¡€
        flat_state = super(type(self), self)._get_flat_state()
        base_req_vec = flat_state[self.dim_network:]  # åŸºç¡€è¯·æ±‚ç‰¹å¾

        # ğŸ”¥ å¤šæ’­å¢å¼ºç‰¹å¾
        num_dests = len(dest_set)
        num_served = len(self.served_destinations) if hasattr(self, 'served_destinations') else 0
        vnf_chain = self.current_request.get('vnf', [])
        avg_bw = self.current_request.get('bandwidth', 0) / max(1, num_dests)

        multicast_features = [
            num_dests / max(1, self.NB_HIGH_LEVEL_GOALS),  # å½’ä¸€åŒ–ç›®æ ‡æ•°
            num_served / max(1, num_dests),  # æœåŠ¡è¿›åº¦
            avg_bw / max(1, self.B_cap),  # å½’ä¸€åŒ–å¹³å‡å¸¦å®½
            self.sharing_strategy / 3.0 if hasattr(self, 'sharing_strategy') else 0.0  # å…±äº«ç­–ç•¥
        ]

        # ç›®æ ‡é›†åˆone-hotç¼–ç 
        dest_encoding = np.zeros(self.NB_HIGH_LEVEL_GOALS)
        for d_idx, dest in enumerate(self.current_request.get('dest', [])):
            if 0 <= d_idx < self.NB_HIGH_LEVEL_GOALS:
                dest_encoding[d_idx] = 1.0

        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        request_vec = np.concatenate([
            base_req_vec[:10],  # åŸºç¡€è¯·æ±‚ç‰¹å¾ (å‰10ç»´)
            multicast_features,  # å¤šæ’­ç‰¹å¾ (4ç»´)
            dest_encoding  # ç›®æ ‡é›†åˆç¼–ç  (NB_HIGH_LEVEL_GOALSç»´)
        ])

        request_vec = torch.tensor(request_vec, dtype=torch.float32)

        return x, self.edge_index, edge_attrs, request_vec

    # ===== æ¥å£é‡å†™ =====
    def get_state(self):
        """ç»Ÿä¸€çŠ¶æ€è·å–æ¥å£"""
        if self.use_gnn:
            return self._get_graph_state()
        return super()._get_flat_state()

    def reset_request(self):
        """é‡ç½®è¯·æ±‚ (è°ƒç”¨çˆ¶ç±»åè¿”å›GNNçŠ¶æ€)"""
        req, _ = super().reset_request()
        return req, self.get_state()

    def step_low_level(self, goal, action):
        """
        æ‰§è¡Œä½å±‚åŠ¨ä½œ (è°ƒç”¨çˆ¶ç±»åè¿”å›GNNçŠ¶æ€)
        """
        _, reward, sub_done, req_done = super().step_low_level(goal, action)
        return self.get_state(), reward, sub_done, req_done

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        super()._clear_cache()
        if hasattr(self, '_dest_dist_cache'):
            self._dest_dist_cache.clear()


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================
if __name__ == "__main__":
    from pathlib import Path
    import hyperparameters as H

    try:
        print("=" * 80)
        print("Initializing Multicast-Aware GNN Env...")
        print("=" * 80)

        topo = H.TOPOLOGY_MATRIX if hasattr(H, 'TOPOLOGY_MATRIX') else np.eye(14)
        dc_nodes = H.DC_NODES if hasattr(H, 'DC_NODES') else [1, 4]
        caps = H.CAPACITIES if hasattr(H, 'CAPACITIES') else {
            'bandwidth': 100, 'cpu': 100, 'memory': 100
        }

        env = SFC_HIRL_Env_GNN(H.INPUT_DIR, topo, dc_nodes, caps, use_gnn=True)

        print("\n" + "=" * 80)
        print("Testing state extraction...")
        print("=" * 80)

        req, state = env.reset_request()

        if req is not None:
            x, ei, ea, r = state
            print(f"\nâœ… Success!")
            print(f"  Node features: {x.shape} (expected: [{env.n}, {env.node_feat_dim}])")
            print(f"  Edge index: {ei.shape}")
            print(f"  Edge attributes: {ea.shape} (expected: [{ei.shape[1]}, {env.edge_feat_dim}])")
            print(f"  Request vector: {r.shape} (expected: [{env.request_dim}])")
            print(f"\n  Request info:")
            print(f"    - ID: {req['id']}")
            print(f"    - Source: {req['source']}")
            print(f"    - Destinations: {req.get('dest', [])}")
            print(f"    - VNF chain: {req.get('vnf', [])}")
        else:
            print("âŒ No request available")

        print("\n" + "=" * 80)

    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback

        traceback.print_exc()